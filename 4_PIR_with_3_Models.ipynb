{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PF2WbgqeMqiQ",
    "outputId": "aef3fec7-201a-46dd-d319-2ca87040e73e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "#https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GsLd96VM-oZ",
    "outputId": "105f4098-fefd-4b48-cbe4-4c5ca290fb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n"
     ]
    }
   ],
   "source": [
    "#EXTRACTING DATA\n",
    "\n",
    "datas = pd.read_csv(\"PIR dataset Duration train.csv\")\n",
    "file = open(\"/Users/asus/notebook/TA/PIR last 30 list dataset train.csv\",\"w\")\n",
    "for z in range(30):\n",
    "  file.write(\"Durasi\")\n",
    "  file.write(str(z+1))\n",
    "  for y in range(4):\n",
    "    file.write(\",Data\")\n",
    "    file.write(str(z+1))\n",
    "    file.write(\"|\")\n",
    "    file.write(\"Pir\")\n",
    "    file.write(str(y+1))\n",
    "  file.write(\",\")\n",
    "file.write(\"Gerakan\")\n",
    "file.write(\"\\n\")\n",
    "\n",
    "percent1 = round(datas.shape[0]/100)\n",
    "percentage = 0\n",
    "\n",
    "for i in range(datas.shape[0]):\n",
    "  if(i%percent1 == 0):\n",
    "    print(str(percentage)+\"%\")\n",
    "    percentage+=1\n",
    "  if(i < 29):\n",
    "    for u in range(29-i):\n",
    "      file.write(\"0,0,0,0,0,\")\n",
    "    for e in range(i+1):\n",
    "      for t in range(5):\n",
    "        file.write(str(datas.iloc[e][t]))\n",
    "        file.write(\",\") \n",
    "  else:\n",
    "    for a in range(30):\n",
    "      for o in range(5):\n",
    "        file.write(str(datas.iloc[i-(29-a)][o]))\n",
    "        file.write(\",\")\n",
    "  file.write(datas.iloc[i][5])\n",
    "  file.write(\"\\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9gMw5axcXGTf"
   },
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "train =pd.read_csv(\"PIR last 30 list dataset train.csv\")\n",
    "\n",
    "# ADD LABEL ENCODER\n",
    "label_encoder = LabelEncoder()\n",
    "train['Gerakan'] = label_encoder.fit_transform(train['Gerakan'])\n",
    "datas_labels = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7QMAZAAXU4c",
    "outputId": "ceb7bc7e-6d05-4f05-aacf-899e773b6931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOITERING' 'NORMAL']\n"
     ]
    }
   ],
   "source": [
    "# LIST OF LABELS\n",
    "print(datas_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBNIHZRyXXzt",
    "outputId": "f72568a2-eb2f-4e51-f0b0-f20b7ea614cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((636852, 30, 5), (636852, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPLIT DATASETS\n",
    "x = train.drop('Gerakan',axis=1)\n",
    "y = train['Gerakan']\n",
    "\n",
    "# RESHAPE DATASET\n",
    "x = x.values.reshape(-1,30,5)   #INPUT 4\n",
    "y = y.values.reshape((-1,1))\n",
    "\n",
    "# CHECK THE SHAPE\n",
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvpG8JGgXqjJ",
    "outputId": "983f898e-109f-4032-bb2e-2bed5a6f1138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095/5095 - 151s - loss: 0.0772 - accuracy: 0.9665 - 151s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "5095/5095 - 151s - loss: 0.0239 - accuracy: 0.9902 - 151s/epoch - 30ms/step\n",
      "Epoch 3/10\n",
      "5095/5095 - 151s - loss: 0.0206 - accuracy: 0.9919 - 151s/epoch - 30ms/step\n",
      "Epoch 4/10\n",
      "5095/5095 - 151s - loss: 0.0171 - accuracy: 0.9930 - 151s/epoch - 30ms/step\n",
      "Epoch 5/10\n",
      "5095/5095 - 150s - loss: 0.0160 - accuracy: 0.9937 - 150s/epoch - 30ms/step\n",
      "Epoch 6/10\n",
      "5095/5095 - 150s - loss: 0.0140 - accuracy: 0.9945 - 150s/epoch - 29ms/step\n",
      "Epoch 7/10\n",
      "5095/5095 - 151s - loss: 0.0126 - accuracy: 0.9950 - 151s/epoch - 30ms/step\n",
      "Epoch 8/10\n",
      "5095/5095 - 152s - loss: 0.0106 - accuracy: 0.9959 - 152s/epoch - 30ms/step\n",
      "Epoch 9/10\n",
      "5095/5095 - 151s - loss: 0.0112 - accuracy: 0.9955 - 151s/epoch - 30ms/step\n",
      "Epoch 10/10\n",
      "5095/5095 - 151s - loss: 0.0095 - accuracy: 0.9963 - 151s/epoch - 30ms/step\n",
      "accuracy: 99.82%\n",
      "Epoch 1/10\n",
      "5095/5095 - 152s - loss: 0.0688 - accuracy: 0.9709 - 152s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "5095/5095 - 151s - loss: 0.0245 - accuracy: 0.9901 - 151s/epoch - 30ms/step\n",
      "Epoch 3/10\n",
      "5095/5095 - 151s - loss: 0.0211 - accuracy: 0.9918 - 151s/epoch - 30ms/step\n",
      "Epoch 4/10\n",
      "5095/5095 - 151s - loss: 0.0168 - accuracy: 0.9933 - 151s/epoch - 30ms/step\n",
      "Epoch 5/10\n",
      "5095/5095 - 151s - loss: 0.0155 - accuracy: 0.9941 - 151s/epoch - 30ms/step\n",
      "Epoch 6/10\n",
      "5095/5095 - 151s - loss: 0.0146 - accuracy: 0.9942 - 151s/epoch - 30ms/step\n",
      "Epoch 7/10\n",
      "5095/5095 - 151s - loss: 0.0138 - accuracy: 0.9947 - 151s/epoch - 30ms/step\n",
      "Epoch 8/10\n",
      "5095/5095 - 151s - loss: 0.0131 - accuracy: 0.9949 - 151s/epoch - 30ms/step\n",
      "Epoch 9/10\n",
      "5095/5095 - 156s - loss: 0.0113 - accuracy: 0.9956 - 156s/epoch - 31ms/step\n",
      "Epoch 10/10\n",
      "5095/5095 - 164s - loss: 0.0108 - accuracy: 0.9957 - 164s/epoch - 32ms/step\n",
      "accuracy: 99.63%\n",
      "Epoch 1/10\n",
      "5095/5095 - 164s - loss: 0.0705 - accuracy: 0.9712 - 164s/epoch - 32ms/step\n",
      "Epoch 2/10\n",
      "5095/5095 - 160s - loss: 0.0243 - accuracy: 0.9902 - 160s/epoch - 31ms/step\n",
      "Epoch 3/10\n",
      "5095/5095 - 160s - loss: 0.0194 - accuracy: 0.9921 - 160s/epoch - 31ms/step\n",
      "Epoch 4/10\n",
      "5095/5095 - 165s - loss: 0.0161 - accuracy: 0.9934 - 165s/epoch - 32ms/step\n",
      "Epoch 5/10\n",
      "5095/5095 - 164s - loss: 0.0156 - accuracy: 0.9941 - 164s/epoch - 32ms/step\n",
      "Epoch 6/10\n",
      "5095/5095 - 314s - loss: 0.0130 - accuracy: 0.9948 - 314s/epoch - 62ms/step\n",
      "Epoch 7/10\n",
      "5095/5095 - 375s - loss: 0.0117 - accuracy: 0.9953 - 375s/epoch - 74ms/step\n",
      "Epoch 8/10\n",
      "5095/5095 - 380s - loss: 0.0125 - accuracy: 0.9952 - 380s/epoch - 75ms/step\n",
      "Epoch 9/10\n",
      "5095/5095 - 374s - loss: 0.0096 - accuracy: 0.9964 - 374s/epoch - 73ms/step\n",
      "Epoch 10/10\n",
      "5095/5095 - 361s - loss: 0.0102 - accuracy: 0.9961 - 361s/epoch - 71ms/step\n",
      "accuracy: 99.75%\n",
      "Epoch 1/10\n",
      "5095/5095 - 341s - loss: 0.0667 - accuracy: 0.9720 - 341s/epoch - 67ms/step\n",
      "Epoch 2/10\n",
      "5095/5095 - 351s - loss: 0.0241 - accuracy: 0.9905 - 351s/epoch - 69ms/step\n",
      "Epoch 3/10\n",
      "5095/5095 - 388s - loss: 0.0186 - accuracy: 0.9924 - 388s/epoch - 76ms/step\n",
      "Epoch 4/10\n",
      "5095/5095 - 374s - loss: 0.0157 - accuracy: 0.9936 - 374s/epoch - 73ms/step\n",
      "Epoch 5/10\n",
      "5095/5095 - 393s - loss: 0.0145 - accuracy: 0.9942 - 393s/epoch - 77ms/step\n",
      "Epoch 6/10\n",
      "5095/5095 - 373s - loss: 0.0125 - accuracy: 0.9949 - 373s/epoch - 73ms/step\n",
      "Epoch 7/10\n",
      "5095/5095 - 372s - loss: 0.0121 - accuracy: 0.9952 - 372s/epoch - 73ms/step\n",
      "Epoch 8/10\n",
      "5095/5095 - 364s - loss: 0.0108 - accuracy: 0.9957 - 364s/epoch - 71ms/step\n",
      "Epoch 9/10\n",
      "5095/5095 - 366s - loss: 0.0104 - accuracy: 0.9960 - 366s/epoch - 72ms/step\n",
      "Epoch 10/10\n",
      "5095/5095 - 367s - loss: 0.0097 - accuracy: 0.9962 - 367s/epoch - 72ms/step\n",
      "accuracy: 99.32%\n",
      "Epoch 1/10\n",
      "5095/5095 - 373s - loss: 0.0765 - accuracy: 0.9675 - 373s/epoch - 73ms/step\n",
      "Epoch 2/10\n",
      "5095/5095 - 380s - loss: 0.0295 - accuracy: 0.9887 - 380s/epoch - 75ms/step\n",
      "Epoch 3/10\n",
      "5095/5095 - 374s - loss: 0.0193 - accuracy: 0.9920 - 374s/epoch - 73ms/step\n",
      "Epoch 4/10\n",
      "5095/5095 - 361s - loss: 0.0162 - accuracy: 0.9934 - 361s/epoch - 71ms/step\n",
      "Epoch 5/10\n",
      "5095/5095 - 393s - loss: 0.0146 - accuracy: 0.9940 - 393s/epoch - 77ms/step\n",
      "Epoch 6/10\n",
      "5095/5095 - 439s - loss: 0.0129 - accuracy: 0.9947 - 439s/epoch - 86ms/step\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)                                            \n",
    "cvscores = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):                                     \n",
    "    x_train, x_test = x[train_index], x[test_index]                             \n",
    "    y_train, y_test = y[train_index], y[test_index]                             \n",
    "    model = keras.Sequential(                                                   \n",
    "        [\n",
    "            keras.Input(shape=(None,5)),\n",
    "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
    "            layers.SimpleRNN(100, activation='tanh'),\n",
    "            layers.Dense(2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2)\n",
    "    scores = model.evaluate(x[test_index], y[test_index], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"Model Accuracy List: \" , cvscores)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "y_pred = model.predict(x)\n",
    "y_pred_values = np.argmax(y_pred, axis = 1)\n",
    "y_pred_values = np.reshape(y_pred_values,(-1,1))\n",
    "print(\"Classification Report Statistic: \")\n",
    "print(classification_report(y, y_pred_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haPG3G_Jp_og"
   },
   "outputs": [],
   "source": [
    "#GRU\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(None,5)),\n",
    "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
    "            layers.GRU(100, activation='tanh'),\n",
    "            layers.Dense(2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2)\n",
    "    scores = model.evaluate(x[test_index], y[test_index], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"Model Accuracy List: \" , cvscores)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "y_pred = model.predict(x)\n",
    "y_pred_values = np.argmax(y_pred, axis = 1)\n",
    "y_pred_values = np.reshape(y_pred_values,(-1,1))\n",
    "print(\"Classification Report Statistic: \")\n",
    "print(classification_report(y, y_pred_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHGWa21LqC2M"
   },
   "outputs": [],
   "source": [
    "#LSTM input 4\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(None,5)),\n",
    "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
    "            layers.LSTM(100, activation='tanh'),\n",
    "            layers.Dense(2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2)\n",
    "    scores = model.evaluate(x[test_index], y[test_index], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"Model Accuracy List: \" , cvscores)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "y_pred = model.predict(x)\n",
    "y_pred_values = np.argmax(y_pred, axis = 1)\n",
    "y_pred_values = np.reshape(y_pred_values,(-1,1))\n",
    "print(\"Classification Report Statistic: \")\n",
    "print(classification_report(y, y_pred_values))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
