{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYG97fymkmPF",
        "outputId": "41982db8-6242-4b1e-c79a-96ccbf866d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "#https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnuj9vrn7aKa",
        "outputId": "bfaf11c5-a164-4fc7-d1b5-541a608b7072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data = 604800 detik\n",
            "Total hari dalam data = 7 hari\n"
          ]
        }
      ],
      "source": [
        "#DATA PREPARATION\n",
        "raw_datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR dataset Time train.csv\")\n",
        "number_of_day = raw_datas.shape[0]/86400\n",
        "print(\"Total data = \" + str(raw_datas.shape[0]) + \" detik\")\n",
        "print(\"Total hari dalam data = \" + str(int(number_of_day)) + \" hari\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMBViWo57Wzv",
        "outputId": "90f09c68-1758-48a1-a264-100dc03ce6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0%\n",
            "1%\n",
            "2%\n",
            "3%\n",
            "4%\n",
            "5%\n",
            "6%\n",
            "7%\n",
            "8%\n",
            "9%\n",
            "10%\n",
            "11%\n",
            "12%\n",
            "13%\n",
            "14%\n",
            "15%\n",
            "16%\n",
            "17%\n",
            "18%\n",
            "19%\n",
            "20%\n",
            "21%\n",
            "22%\n",
            "23%\n",
            "24%\n",
            "25%\n",
            "26%\n",
            "27%\n",
            "28%\n",
            "29%\n",
            "30%\n",
            "31%\n",
            "32%\n",
            "33%\n",
            "34%\n",
            "35%\n",
            "36%\n",
            "37%\n",
            "38%\n",
            "39%\n",
            "40%\n",
            "41%\n",
            "42%\n",
            "43%\n",
            "44%\n",
            "45%\n",
            "46%\n",
            "47%\n",
            "48%\n",
            "49%\n",
            "50%\n",
            "51%\n",
            "52%\n",
            "53%\n",
            "54%\n",
            "55%\n",
            "56%\n",
            "57%\n",
            "58%\n",
            "59%\n",
            "60%\n",
            "61%\n",
            "62%\n",
            "63%\n",
            "64%\n",
            "65%\n",
            "66%\n",
            "67%\n",
            "68%\n",
            "69%\n",
            "70%\n",
            "71%\n",
            "72%\n",
            "73%\n",
            "74%\n",
            "75%\n",
            "76%\n",
            "77%\n",
            "78%\n",
            "79%\n",
            "80%\n",
            "81%\n",
            "82%\n",
            "83%\n",
            "84%\n",
            "85%\n",
            "86%\n",
            "87%\n",
            "88%\n",
            "89%\n",
            "90%\n",
            "91%\n",
            "92%\n",
            "93%\n",
            "94%\n",
            "95%\n",
            "96%\n",
            "97%\n",
            "98%\n",
            "99%\n",
            "100%\n"
          ]
        }
      ],
      "source": [
        "#EXTRACTING DATA\n",
        "\n",
        "datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR dataset Duration train.csv\")\n",
        "file = open(\"/content/drive/MyDrive/Dann Dataset/PIR last 30 list dataset train.csv\",\"w\")\n",
        "for z in range(30):\n",
        "  file.write(\"Durasi\")\n",
        "  file.write(str(z+1))\n",
        "  for y in range(4):\n",
        "    file.write(\",Data\")\n",
        "    file.write(str(z+1))\n",
        "    file.write(\"|\")\n",
        "    file.write(\"Pir\")\n",
        "    file.write(str(y+1))\n",
        "  file.write(\",\")\n",
        "file.write(\"Gerakan\")\n",
        "file.write(\"\\n\")\n",
        "\n",
        "percent1 = round(datas.shape[0]/100)\n",
        "percentage = 0\n",
        "\n",
        "for i in range(datas.shape[0]):\n",
        "  if(i%percent1 == 0):\n",
        "    print(str(percentage)+\"%\")\n",
        "    percentage+=1\n",
        "  if(i < 29):\n",
        "    for u in range(29-i):\n",
        "      file.write(\"0,0,0,0,0,\")\n",
        "    for e in range(i+1):\n",
        "      for t in range(5):\n",
        "        file.write(str(datas.iloc[e][t]))\n",
        "        file.write(\",\") \n",
        "  else:\n",
        "    for a in range(30):\n",
        "      for o in range(5):\n",
        "        file.write(str(datas.iloc[i-(29-a)][o]))\n",
        "        file.write(\",\")\n",
        "  file.write(datas.iloc[i][5])\n",
        "  file.write(\"\\n\")\n",
        "\n",
        "print(\"100%\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AWQsUdja77bD"
      },
      "outputs": [],
      "source": [
        "# LOAD DATASET\n",
        "feature_data =pd.read_csv(\"drive/MyDrive/Dann Dataset/PIR last 30 list dataset train.csv\")\n",
        "\n",
        "# ADD LABEL ENCODER\n",
        "label_encoder = LabelEncoder()\n",
        "feature_data['Gerakan'] = label_encoder.fit_transform(feature_data['Gerakan'])\n",
        "datas_labels = label_encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDaHAU7eD4CR",
        "outputId": "8d7dfa7b-5540-4354-c56c-1558b17c8fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LOITERING' 'NORMAL']\n"
          ]
        }
      ],
      "source": [
        "# LIST OF LABELS\n",
        "print(datas_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEc59ruoD6MC",
        "outputId": "6857fb35-a74e-4640-b10b-d27466744554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (140202, 30, 5) (140202, 1)\n",
            "Test: (60087, 30, 5) (60087, 1)\n"
          ]
        }
      ],
      "source": [
        "x = feature_data.drop('Gerakan',axis=1)\n",
        "y = feature_data['Gerakan']\n",
        "\n",
        "# RESHAPE DATASET\n",
        "x = x.values.reshape(-1,30,5)   #INPUT 4\n",
        "y = y.values.reshape((-1,1))\n",
        "\n",
        "# SPLIT DATASET\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) #Split Dataset Train 70% dan Test 30%\n",
        "\n",
        "# CHECK THE SHAPE\n",
        "print(\"Train:\", x_train.shape , y_train.shape)\n",
        "print(\"Test:\",x_test.shape , y_test.shape)\n",
        "\n",
        "# SET TOTAL FOLD\n",
        "total_fold = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a4z8GH7_qgA",
        "outputId": "b5e7cb91-57f2-475a-b31c-fa5b398156c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6899 - accuracy: 0.5538 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.6212 - accuracy: 0.6593 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.5638 - accuracy: 0.7046 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.5219 - accuracy: 0.7327 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.4455 - accuracy: 0.7994 - 34s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3406 - accuracy: 0.8649 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2705 - accuracy: 0.8980 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2274 - accuracy: 0.9158 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.2015 - accuracy: 0.9262 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1800 - accuracy: 0.9342 - 32s/epoch - 29ms/step\n",
            "accuracy: 93.97%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6630 - accuracy: 0.6039 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.5908 - accuracy: 0.6727 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 34s - loss: 0.5418 - accuracy: 0.7169 - 34s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4706 - accuracy: 0.7787 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3756 - accuracy: 0.8439 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3014 - accuracy: 0.8834 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2508 - accuracy: 0.9084 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2174 - accuracy: 0.9223 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1942 - accuracy: 0.9308 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1806 - accuracy: 0.9348 - 32s/epoch - 29ms/step\n",
            "accuracy: 94.49%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6709 - accuracy: 0.5779 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 34s - loss: 0.5954 - accuracy: 0.6708 - 34s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.5254 - accuracy: 0.7317 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4293 - accuracy: 0.8070 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3463 - accuracy: 0.8575 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.2899 - accuracy: 0.8870 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2469 - accuracy: 0.9064 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2113 - accuracy: 0.9210 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1836 - accuracy: 0.9318 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 34s - loss: 0.1669 - accuracy: 0.9375 - 34s/epoch - 30ms/step\n",
            "accuracy: 92.52%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6997 - accuracy: 0.5573 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 32s - loss: 0.5918 - accuracy: 0.6722 - 32s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.5351 - accuracy: 0.7195 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4769 - accuracy: 0.7723 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3820 - accuracy: 0.8423 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3132 - accuracy: 0.8768 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2652 - accuracy: 0.8988 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 34s - loss: 0.2255 - accuracy: 0.9159 - 34s/epoch - 30ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1987 - accuracy: 0.9266 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1801 - accuracy: 0.9334 - 32s/epoch - 29ms/step\n",
            "accuracy: 93.16%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.7001 - accuracy: 0.5429 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 32s - loss: 0.6473 - accuracy: 0.6132 - 32s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.6020 - accuracy: 0.6686 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.5624 - accuracy: 0.7003 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.5179 - accuracy: 0.7380 - 34s/epoch - 31ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.4337 - accuracy: 0.8112 - 33s/epoch - 30ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.3230 - accuracy: 0.8783 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2622 - accuracy: 0.9038 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.2248 - accuracy: 0.9178 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.2006 - accuracy: 0.9267 - 32s/epoch - 29ms/step\n",
            "accuracy: 91.49%\n",
            "Model Accuracy List:  [93.97311210632324, 94.49021220207214, 92.52139925956726, 93.1562066078186, 91.48716330528259]\n",
            "93.13% (+/- 1.06%)\n"
          ]
        }
      ],
      "source": [
        "#RNN BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4), #metode optimizer default\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK7jRvXLFQMh",
        "outputId": "f627f092-3b8e-482b-938e-e611b314a073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 36s - loss: 0.1879 - accuracy: 0.9173 - 36s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0607 - accuracy: 0.9769 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0375 - accuracy: 0.9857 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0326 - accuracy: 0.9870 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0579 - accuracy: 0.9814 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 35s - loss: 0.0320 - accuracy: 0.9877 - 35s/epoch - 31ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 35s - loss: 0.0229 - accuracy: 0.9909 - 35s/epoch - 31ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0221 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0223 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0240 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.44%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.1944 - accuracy: 0.9121 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0534 - accuracy: 0.9799 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 34s - loss: 0.0375 - accuracy: 0.9854 - 34s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 34s - loss: 0.0293 - accuracy: 0.9881 - 34s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0281 - accuracy: 0.9887 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0246 - accuracy: 0.9898 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0226 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0213 - accuracy: 0.9914 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0232 - accuracy: 0.9910 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0161 - accuracy: 0.9932 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.42%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 36s - loss: 0.1704 - accuracy: 0.9220 - 36s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0508 - accuracy: 0.9807 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.0350 - accuracy: 0.9865 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0395 - accuracy: 0.9854 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0243 - accuracy: 0.9904 - 33s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0257 - accuracy: 0.9896 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0266 - accuracy: 0.9896 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 34s - loss: 0.0205 - accuracy: 0.9919 - 34s/epoch - 31ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0219 - accuracy: 0.9912 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0205 - accuracy: 0.9913 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.10%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.1727 - accuracy: 0.9257 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0643 - accuracy: 0.9763 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0462 - accuracy: 0.9822 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0328 - accuracy: 0.9870 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.0301 - accuracy: 0.9879 - 34s/epoch - 31ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0273 - accuracy: 0.9890 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0247 - accuracy: 0.9900 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0242 - accuracy: 0.9901 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0194 - accuracy: 0.9923 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0179 - accuracy: 0.9928 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.24%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.2104 - accuracy: 0.9060 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 34s - loss: 0.0566 - accuracy: 0.9788 - 34s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0379 - accuracy: 0.9856 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0406 - accuracy: 0.9849 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0305 - accuracy: 0.9877 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0258 - accuracy: 0.9897 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0202 - accuracy: 0.9920 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0227 - accuracy: 0.9910 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0199 - accuracy: 0.9914 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 34s - loss: 0.0189 - accuracy: 0.9925 - 34s/epoch - 30ms/step\n",
            "accuracy: 99.59%\n",
            "Model Accuracy List:  [99.4365394115448, 99.41514134407043, 99.09771680831909, 99.23680424690247, 99.58987236022949]\n",
            "99.36% (+/- 0.17%)\n"
          ]
        }
      ],
      "source": [
        "#RNN AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T9kIya-tb_Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f9ab48-67a1-4316-fb21-9b3e372afe83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1122/1122 - 158s - loss: 0.6897 - accuracy: 0.5373 - 158s/epoch - 141ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 131s - loss: 0.6679 - accuracy: 0.5809 - 131s/epoch - 117ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6613 - accuracy: 0.6095 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.6561 - accuracy: 0.6216 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6515 - accuracy: 0.6264 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 116s - loss: 0.6474 - accuracy: 0.6294 - 116s/epoch - 103ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 114s - loss: 0.6435 - accuracy: 0.6315 - 114s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6398 - accuracy: 0.6341 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6362 - accuracy: 0.6367 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.6326 - accuracy: 0.6394 - 116s/epoch - 104ms/step\n",
            "accuracy: 63.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.6881 - accuracy: 0.5133 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 114s - loss: 0.6755 - accuracy: 0.5149 - 114s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6673 - accuracy: 0.5721 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 115s - loss: 0.6607 - accuracy: 0.6107 - 115s/epoch - 103ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.6551 - accuracy: 0.6215 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.6502 - accuracy: 0.6273 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6458 - accuracy: 0.6300 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6415 - accuracy: 0.6322 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6375 - accuracy: 0.6347 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.6335 - accuracy: 0.6367 - 116s/epoch - 103ms/step\n",
            "accuracy: 63.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.6894 - accuracy: 0.5385 - 117s/epoch - 104ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 115s - loss: 0.6770 - accuracy: 0.5655 - 115s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6691 - accuracy: 0.5985 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 113s - loss: 0.6623 - accuracy: 0.6130 - 113s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6578 - accuracy: 0.6180 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.6536 - accuracy: 0.6206 - 114s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6497 - accuracy: 0.6251 - 117s/epoch - 105ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6458 - accuracy: 0.6281 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6420 - accuracy: 0.6314 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 117s - loss: 0.6383 - accuracy: 0.6347 - 117s/epoch - 104ms/step\n",
            "accuracy: 63.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.6908 - accuracy: 0.5096 - 117s/epoch - 104ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.6762 - accuracy: 0.5405 - 116s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6682 - accuracy: 0.5808 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 115s - loss: 0.6615 - accuracy: 0.6097 - 115s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.6559 - accuracy: 0.6161 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 115s - loss: 0.6510 - accuracy: 0.6215 - 115s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6465 - accuracy: 0.6247 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.6421 - accuracy: 0.6277 - 114s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.6380 - accuracy: 0.6308 - 116s/epoch - 103ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 113s - loss: 0.6341 - accuracy: 0.6331 - 113s/epoch - 101ms/step\n",
            "accuracy: 63.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_9_layer_call_fn, gru_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.6846 - accuracy: 0.5129 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.6721 - accuracy: 0.5434 - 116s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 114s - loss: 0.6648 - accuracy: 0.5658 - 114s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.6591 - accuracy: 0.5809 - 116s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 114s - loss: 0.6541 - accuracy: 0.5917 - 114s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 116s - loss: 0.6496 - accuracy: 0.5992 - 116s/epoch - 104ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 116s - loss: 0.6456 - accuracy: 0.6060 - 116s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.6417 - accuracy: 0.6120 - 114s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.6381 - accuracy: 0.6175 - 116s/epoch - 103ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 114s - loss: 0.6344 - accuracy: 0.6211 - 114s/epoch - 101ms/step\n",
            "accuracy: 62.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [63.84579539299011, 63.92781734466553, 63.291728496551514, 63.40941786766052, 62.767475843429565]\n",
            "63.45% (+/- 0.42%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#GRU BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2opkRY-NnnGE",
        "outputId": "d81c9be2-97a0-4a1f-a2c8-2073c1c47234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 119s - loss: 0.1998 - accuracy: 0.9084 - 119s/epoch - 106ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 117s - loss: 0.0614 - accuracy: 0.9747 - 117s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 114s - loss: 0.0339 - accuracy: 0.9871 - 114s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 117s - loss: 0.1209 - accuracy: 0.9736 - 117s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.0238 - accuracy: 0.9911 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.0193 - accuracy: 0.9927 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.0146 - accuracy: 0.9947 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 115s - loss: 0.0141 - accuracy: 0.9946 - 115s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 117s - loss: 0.0139 - accuracy: 0.9946 - 117s/epoch - 104ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.0122 - accuracy: 0.9955 - 116s/epoch - 103ms/step\n",
            "accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.2022 - accuracy: 0.9043 - 117s/epoch - 105ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0523 - accuracy: 0.9788 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 116s - loss: 0.0310 - accuracy: 0.9878 - 116s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.0225 - accuracy: 0.9909 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.0185 - accuracy: 0.9923 - 116s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.0183 - accuracy: 0.9927 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.0155 - accuracy: 0.9935 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.0140 - accuracy: 0.9945 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 115s - loss: 0.0145 - accuracy: 0.9945 - 115s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 118s - loss: 0.0116 - accuracy: 0.9956 - 118s/epoch - 105ms/step\n",
            "accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.1896 - accuracy: 0.9134 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 114s - loss: 0.0560 - accuracy: 0.9769 - 114s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.0357 - accuracy: 0.9867 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.0248 - accuracy: 0.9902 - 116s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 114s - loss: 0.0198 - accuracy: 0.9919 - 114s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 117s - loss: 0.0158 - accuracy: 0.9936 - 117s/epoch - 104ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 116s - loss: 0.0289 - accuracy: 0.9918 - 116s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.0115 - accuracy: 0.9954 - 114s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.0115 - accuracy: 0.9953 - 116s/epoch - 104ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 114s - loss: 0.0130 - accuracy: 0.9948 - 114s/epoch - 102ms/step\n",
            "accuracy: 98.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_16_layer_call_fn, gru_cell_16_layer_call_and_return_conditional_losses, gru_cell_17_layer_call_fn, gru_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 118s - loss: 0.2009 - accuracy: 0.9087 - 118s/epoch - 105ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0553 - accuracy: 0.9775 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 116s - loss: 0.0317 - accuracy: 0.9880 - 116s/epoch - 103ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.0223 - accuracy: 0.9914 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6613 - accuracy: 0.8001 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 113s - loss: 0.1165 - accuracy: 0.9584 - 113s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 115s - loss: 0.0547 - accuracy: 0.9802 - 115s/epoch - 103ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 115s - loss: 0.0394 - accuracy: 0.9854 - 115s/epoch - 103ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 113s - loss: 0.0300 - accuracy: 0.9887 - 113s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.0250 - accuracy: 0.9903 - 116s/epoch - 103ms/step\n",
            "accuracy: 98.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_18_layer_call_fn, gru_cell_18_layer_call_and_return_conditional_losses, gru_cell_19_layer_call_fn, gru_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 119s - loss: 0.2170 - accuracy: 0.8975 - 119s/epoch - 106ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0553 - accuracy: 0.9775 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 113s - loss: 0.0344 - accuracy: 0.9871 - 113s/epoch - 100ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.0234 - accuracy: 0.9906 - 116s/epoch - 103ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 115s - loss: 0.0185 - accuracy: 0.9926 - 115s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 113s - loss: 0.0252 - accuracy: 0.9918 - 113s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 115s - loss: 0.0152 - accuracy: 0.9938 - 115s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.0141 - accuracy: 0.9944 - 114s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 113s - loss: 0.0137 - accuracy: 0.9945 - 113s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 115s - loss: 0.0119 - accuracy: 0.9953 - 115s/epoch - 102ms/step\n",
            "accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [99.5756208896637, 99.33668375015259, 98.76961708068848, 98.98002743721008, 99.33309555053711]\n",
            "99.20% (+/- 0.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#GRU AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzMQ1Rf4n9qQ",
        "outputId": "1d0fc74f-c4c6-40c4-b56e-68767478b6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 126s - loss: 0.6782 - accuracy: 0.5242 - 126s/epoch - 112ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6670 - accuracy: 0.6303 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 124s - loss: 0.6571 - accuracy: 0.6869 - 124s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6471 - accuracy: 0.6965 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.6366 - accuracy: 0.6991 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 122s - loss: 0.6260 - accuracy: 0.7011 - 122s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6154 - accuracy: 0.7016 - 125s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.6049 - accuracy: 0.7014 - 125s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.5950 - accuracy: 0.7005 - 125s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.5862 - accuracy: 0.6995 - 124s/epoch - 111ms/step\n",
            "accuracy: 70.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.6997 - accuracy: 0.4280 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6884 - accuracy: 0.4960 - 124s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6791 - accuracy: 0.5184 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6691 - accuracy: 0.5883 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.6591 - accuracy: 0.6584 - 125s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6503 - accuracy: 0.6852 - 125s/epoch - 112ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 126s - loss: 0.6413 - accuracy: 0.6920 - 126s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 123s - loss: 0.6319 - accuracy: 0.6962 - 123s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.6221 - accuracy: 0.6993 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.6121 - accuracy: 0.7000 - 125s/epoch - 112ms/step\n",
            "accuracy: 69.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.6864 - accuracy: 0.5072 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6763 - accuracy: 0.5973 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6657 - accuracy: 0.6623 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6570 - accuracy: 0.6914 - 125s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 123s - loss: 0.6483 - accuracy: 0.6968 - 123s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6389 - accuracy: 0.6995 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.6291 - accuracy: 0.7010 - 124s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.6189 - accuracy: 0.7016 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.6089 - accuracy: 0.7020 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.5992 - accuracy: 0.7014 - 124s/epoch - 111ms/step\n",
            "accuracy: 69.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.6917 - accuracy: 0.5785 - 127s/epoch - 113ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6768 - accuracy: 0.6708 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6669 - accuracy: 0.6979 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 123s - loss: 0.6571 - accuracy: 0.7016 - 123s/epoch - 110ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 126s - loss: 0.6469 - accuracy: 0.7022 - 126s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6360 - accuracy: 0.7031 - 125s/epoch - 112ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6248 - accuracy: 0.7016 - 125s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.6135 - accuracy: 0.7012 - 125s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.6026 - accuracy: 0.6996 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.5927 - accuracy: 0.6977 - 125s/epoch - 111ms/step\n",
            "accuracy: 69.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.6843 - accuracy: 0.5172 - 127s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.6688 - accuracy: 0.6362 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6575 - accuracy: 0.6814 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 126s - loss: 0.6467 - accuracy: 0.6913 - 126s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 123s - loss: 0.6359 - accuracy: 0.6960 - 123s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 124s - loss: 0.6246 - accuracy: 0.6989 - 124s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6127 - accuracy: 0.7009 - 125s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.6017 - accuracy: 0.7015 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 126s - loss: 0.5919 - accuracy: 0.7019 - 126s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.5834 - accuracy: 0.7010 - 125s/epoch - 111ms/step\n",
            "accuracy: 70.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [70.0082004070282, 69.80849504470825, 69.86448168754578, 69.57560777664185, 70.44935822486877]\n",
            "69.94% (+/- 0.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#LSTM BEFORE TUNING \n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqJ27C2noahB",
        "outputId": "d209d1f3-a54f-4634-c07e-d0f49848194f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.2203 - accuracy: 0.9027 - 127s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0972 - accuracy: 0.9645 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0531 - accuracy: 0.9795 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0409 - accuracy: 0.9837 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.0298 - accuracy: 0.9881 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0297 - accuracy: 0.9890 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.0232 - accuracy: 0.9906 - 124s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0198 - accuracy: 0.9915 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0179 - accuracy: 0.9928 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0178 - accuracy: 0.9927 - 125s/epoch - 111ms/step\n",
            "accuracy: 98.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.2340 - accuracy: 0.8967 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0835 - accuracy: 0.9667 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0727 - accuracy: 0.9729 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0454 - accuracy: 0.9824 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 124s - loss: 0.0334 - accuracy: 0.9869 - 124s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 124s - loss: 0.0366 - accuracy: 0.9868 - 124s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.0246 - accuracy: 0.9903 - 125s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0285 - accuracy: 0.9892 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.0186 - accuracy: 0.9923 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0189 - accuracy: 0.9920 - 125s/epoch - 111ms/step\n",
            "accuracy: 98.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 128s - loss: 0.2444 - accuracy: 0.8944 - 128s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0871 - accuracy: 0.9653 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0551 - accuracy: 0.9787 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 126s - loss: 0.0393 - accuracy: 0.9845 - 126s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 126s - loss: 0.0307 - accuracy: 0.9878 - 126s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0282 - accuracy: 0.9889 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 126s - loss: 0.0221 - accuracy: 0.9910 - 126s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.0216 - accuracy: 0.9916 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0171 - accuracy: 0.9931 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0185 - accuracy: 0.9923 - 125s/epoch - 112ms/step\n",
            "accuracy: 98.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 128s - loss: 0.2332 - accuracy: 0.8966 - 128s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.1086 - accuracy: 0.9583 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 124s - loss: 0.0581 - accuracy: 0.9771 - 124s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 124s - loss: 0.0612 - accuracy: 0.9797 - 124s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.0337 - accuracy: 0.9872 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0280 - accuracy: 0.9890 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.0249 - accuracy: 0.9902 - 124s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 124s - loss: 0.0233 - accuracy: 0.9905 - 124s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0243 - accuracy: 0.9902 - 125s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.0192 - accuracy: 0.9922 - 124s/epoch - 111ms/step\n",
            "accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.2265 - accuracy: 0.9012 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0805 - accuracy: 0.9678 - 125s/epoch - 112ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0721 - accuracy: 0.9748 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0442 - accuracy: 0.9833 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 127s - loss: 0.0347 - accuracy: 0.9868 - 127s/epoch - 113ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 127s - loss: 0.0276 - accuracy: 0.9893 - 127s/epoch - 113ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 123s - loss: 0.0212 - accuracy: 0.9913 - 123s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0243 - accuracy: 0.9905 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 126s - loss: 0.0160 - accuracy: 0.9936 - 126s/epoch - 113ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 126s - loss: 0.0187 - accuracy: 0.9928 - 126s/epoch - 112ms/step\n",
            "accuracy: 99.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [98.38094115257263, 98.70190024375916, 98.84807467460632, 99.4436502456665, 99.08345341682434]\n",
            "98.89% (+/- 0.36%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#LSTM AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxWL8XMMQBP"
      },
      "source": [
        "Get list of accuracy, precision, recallandf1\n",
        "Pengujian Data Testing\n",
        "- Load Model untuk klasifikasi data Testing\n",
        "- Model sudah di Load lalu melakukan Predict terhadap data Testing\n",
        "- Simpan data Hasil Predict untuk codingan selanjutnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bz3MmtKu0Rz",
        "outputId": "3f42541d-4a61-4179-e5d6-14233032d95e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 15s 8ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 28s 15ms/step\n",
            "1878/1878 [==============================] - 28s 14ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 28s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n"
          ]
        }
      ],
      "source": [
        "#RNN K-FOLD BEFORE TUNING \n",
        "file_rnn_fold_before = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_before = [(pickle.load(open(file_rnn_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_before = [(loaded_model_rnn_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_before = [(np.argmax(y_pred_rnn_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_before[ypvc] = np.reshape(y_pred_values_rnn_before[ypvc],(-1,1))\n",
        "result_rnn_before = [(classification_report(y_test, y_pred_values_rnn_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#RNN K-FOLD AFTER TUNING \n",
        "file_rnn_fold_after = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_after = [(pickle.load(open(file_rnn_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_after = [(loaded_model_rnn_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_after = [(np.argmax(y_pred_rnn_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_after[ypvc] = np.reshape(y_pred_values_rnn_after[ypvc],(-1,1))\n",
        "result_rnn_after = [(classification_report(y_test, y_pred_values_rnn_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU K-FOLD BEFORE TUNING\n",
        "file_gru_fold_before = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_before = [(pickle.load(open(file_gru_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_before = [(loaded_model_gru_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_before = [(np.argmax(y_pred_gru_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_before[ypvc] = np.reshape(y_pred_values_gru_before[ypvc],(-1,1))\n",
        "result_gru_before = [(classification_report(y_test, y_pred_values_gru_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU K-FOLD AFTER TUNING\n",
        "file_gru_fold_after = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_after = [(pickle.load(open(file_gru_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_after = [(loaded_model_gru_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_after = [(np.argmax(y_pred_gru_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_after[ypvc] = np.reshape(y_pred_values_gru_after[ypvc],(-1,1))\n",
        "result_gru_after = [(classification_report(y_test, y_pred_values_gru_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM K-FOLD BEFORE TUNING\n",
        "file_lstm_fold_before = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_before = [(pickle.load(open(file_lstm_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_before = [(loaded_model_lstm_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_before = [(np.argmax(y_pred_lstm_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_before[ypvc] = np.reshape(y_pred_values_lstm_before[ypvc],(-1,1))\n",
        "result_lstm_before = [(classification_report(y_test, y_pred_values_lstm_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM K-FOLD AFTER TUNING\n",
        "file_lstm_fold_after = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_after = [(pickle.load(open(file_lstm_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_after = [(loaded_model_lstm_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_after = [(np.argmax(y_pred_lstm_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_after[ypvc] = np.reshape(y_pred_values_lstm_after[ypvc],(-1,1))\n",
        "result_lstm_after = [(classification_report(y_test, y_pred_values_lstm_after[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4NUtnXXOStu"
      },
      "source": [
        "Buat List untuk menampung dari Hasil dari Fold untuk Precision,Recall,Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H64u5UGcxHJF"
      },
      "outputs": [],
      "source": [
        "precision_list_before = {}\n",
        "precision_list_after = {}\n",
        "recall_list_before = {}\n",
        "recall_list_after = {}\n",
        "accuracy_list_before = {}\n",
        "accuracy_list_after = {}\n",
        "f1_list_before = {}\n",
        "f1_list_after = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8SnDZvIN6zp"
      },
      "source": [
        "Rata-rata dari Precision,Recall,F1-Score,Accuracy\n",
        "\n",
        "Mengambil data hasil predict pada codingan sebelumnya\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "T36Kk96Lu-MY"
      },
      "outputs": [],
      "source": [
        "for sco in range(total_fold):\n",
        "  precision_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['precision'] , result_gru_before[sco]['weighted avg']['precision'], result_lstm_before[sco]['weighted avg']['precision']]\n",
        "  precision_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['precision'] , result_gru_after[sco]['weighted avg']['precision'], result_lstm_after[sco]['weighted avg']['precision']]\n",
        "  recall_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['recall'] , result_gru_before[sco]['weighted avg']['recall'], result_lstm_before[sco]['weighted avg']['recall']]\n",
        "  recall_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['recall'] , result_gru_after[sco]['weighted avg']['recall'], result_lstm_after[sco]['weighted avg']['recall']]\n",
        "  f1_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['f1-score'] , result_gru_before[sco]['weighted avg']['f1-score'], result_lstm_before[sco]['weighted avg']['f1-score']]\n",
        "  f1_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['f1-score'] , result_gru_after[sco]['weighted avg']['f1-score'], result_lstm_after[sco]['weighted avg']['f1-score']]\n",
        "  accuracy_list_before[(sco+1)] = [result_rnn_before[sco]['accuracy'] , result_gru_before[sco]['accuracy'], result_lstm_before[sco]['accuracy']]\n",
        "  accuracy_list_after[(sco+1)] = [result_rnn_after[sco]['accuracy'] , result_gru_after[sco]['accuracy'], result_lstm_after[sco]['accuracy']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY3txyT23pYf"
      },
      "source": [
        "Menampilkan Hasil Predict Tiap Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EKzWuXez4jKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e428ce68-b0a7-4b6d-8f6d-8672153d3d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Precision K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.943           0.695      0.734     \n",
            "2        0.944           0.728      0.747     \n",
            "3        0.929           0.718      0.745     \n",
            "4        0.938           0.710      0.731     \n",
            "5        0.924           0.679      0.744     \n",
            "\n",
            "\n",
            "      Precision K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.986     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.989      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      Recall K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.639      0.697     \n",
            "2        0.943           0.636      0.699     \n",
            "3        0.925           0.633      0.700     \n",
            "4        0.932           0.635      0.696     \n",
            "5        0.915           0.624      0.701     \n",
            "\n",
            "\n",
            "      Recall K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.639      0.697     \n",
            "2        0.943           0.636      0.699     \n",
            "3        0.925           0.633      0.700     \n",
            "4        0.932           0.635      0.696     \n",
            "5        0.915           0.624      0.701     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.615      0.687     \n",
            "2        0.943           0.600      0.686     \n",
            "3        0.924           0.597      0.687     \n",
            "4        0.932           0.603      0.686     \n",
            "5        0.914           0.597      0.689     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}