{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYG97fymkmPF",
        "outputId": "cff859f0-7aa3-4ef6-e7c3-df1e5196a166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "#https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnuj9vrn7aKa",
        "outputId": "d5c0855d-f656-47bd-8784-46444013468b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data = 604800 detik\n",
            "Total hari dalam data = 7 hari\n"
          ]
        }
      ],
      "source": [
        "#DATA PREPARATION\n",
        "raw_datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR dataset Time train.csv\")\n",
        "number_of_day = raw_datas.shape[0]/86400\n",
        "print(\"Total data = \" + str(raw_datas.shape[0]) + \" detik\")\n",
        "print(\"Total hari dalam data = \" + str(int(number_of_day)) + \" hari\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMBViWo57Wzv",
        "outputId": "90f09c68-1758-48a1-a264-100dc03ce6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0%\n",
            "1%\n",
            "2%\n",
            "3%\n",
            "4%\n",
            "5%\n",
            "6%\n",
            "7%\n",
            "8%\n",
            "9%\n",
            "10%\n",
            "11%\n",
            "12%\n",
            "13%\n",
            "14%\n",
            "15%\n",
            "16%\n",
            "17%\n",
            "18%\n",
            "19%\n",
            "20%\n",
            "21%\n",
            "22%\n",
            "23%\n",
            "24%\n",
            "25%\n",
            "26%\n",
            "27%\n",
            "28%\n",
            "29%\n",
            "30%\n",
            "31%\n",
            "32%\n",
            "33%\n",
            "34%\n",
            "35%\n",
            "36%\n",
            "37%\n",
            "38%\n",
            "39%\n",
            "40%\n",
            "41%\n",
            "42%\n",
            "43%\n",
            "44%\n",
            "45%\n",
            "46%\n",
            "47%\n",
            "48%\n",
            "49%\n",
            "50%\n",
            "51%\n",
            "52%\n",
            "53%\n",
            "54%\n",
            "55%\n",
            "56%\n",
            "57%\n",
            "58%\n",
            "59%\n",
            "60%\n",
            "61%\n",
            "62%\n",
            "63%\n",
            "64%\n",
            "65%\n",
            "66%\n",
            "67%\n",
            "68%\n",
            "69%\n",
            "70%\n",
            "71%\n",
            "72%\n",
            "73%\n",
            "74%\n",
            "75%\n",
            "76%\n",
            "77%\n",
            "78%\n",
            "79%\n",
            "80%\n",
            "81%\n",
            "82%\n",
            "83%\n",
            "84%\n",
            "85%\n",
            "86%\n",
            "87%\n",
            "88%\n",
            "89%\n",
            "90%\n",
            "91%\n",
            "92%\n",
            "93%\n",
            "94%\n",
            "95%\n",
            "96%\n",
            "97%\n",
            "98%\n",
            "99%\n",
            "100%\n"
          ]
        }
      ],
      "source": [
        "#EXTRACTING DATA\n",
        "\n",
        "datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR dataset Duration train.csv\")\n",
        "file = open(\"/content/drive/MyDrive/Dann Dataset/PIR last 30 list dataset train.csv\",\"w\")\n",
        "for z in range(30):\n",
        "  file.write(\"Durasi\")\n",
        "  file.write(str(z+1))\n",
        "  for y in range(4):\n",
        "    file.write(\",Data\")\n",
        "    file.write(str(z+1))\n",
        "    file.write(\"|\")\n",
        "    file.write(\"Pir\")\n",
        "    file.write(str(y+1))\n",
        "  file.write(\",\")\n",
        "file.write(\"Gerakan\")\n",
        "file.write(\"\\n\")\n",
        "\n",
        "percent1 = round(datas.shape[0]/100)\n",
        "percentage = 0\n",
        "\n",
        "for i in range(datas.shape[0]):\n",
        "  if(i%percent1 == 0):\n",
        "    print(str(percentage)+\"%\")\n",
        "    percentage+=1\n",
        "  if(i < 29):\n",
        "    for u in range(29-i):\n",
        "      file.write(\"0,0,0,0,0,\")\n",
        "    for e in range(i+1):\n",
        "      for t in range(5):\n",
        "        file.write(str(datas.iloc[e][t]))\n",
        "        file.write(\",\") \n",
        "  else:\n",
        "    for a in range(30):\n",
        "      for o in range(5):\n",
        "        file.write(str(datas.iloc[i-(29-a)][o]))\n",
        "        file.write(\",\")\n",
        "  file.write(datas.iloc[i][5])\n",
        "  file.write(\"\\n\")\n",
        "\n",
        "print(\"100%\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BEFORE EXTRACTION FEATURE\n",
        "datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR dataset Duration train.csv\", sep=';', header=0)\n",
        "print(datas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83zEfZC3NyJ",
        "outputId": "b5294bf9-17b0-49b7-f181-2ec503d2c839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Durasi,Pir_1,Pir2,Pir3,Pir4,Gerakan\n",
            "0                        37,0,0,0,0,NORMAL\n",
            "1                         1,0,0,1,0,NORMAL\n",
            "2                         2,0,1,0,0,NORMAL\n",
            "3                         2,0,0,0,1,NORMAL\n",
            "4                         4,0,1,0,0,NORMAL\n",
            "...                                    ...\n",
            "200284                 1,0,1,0,0,LOITERING\n",
            "200285                 1,1,0,0,0,LOITERING\n",
            "200286                 1,0,1,0,0,LOITERING\n",
            "200287                 1,1,0,0,0,LOITERING\n",
            "200288                 1,1,0,1,0,LOITERING\n",
            "\n",
            "[200289 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- data per 30 sampel\n",
        "- data yang sama 30 sampel dijadiin 1 row "
      ],
      "metadata": {
        "id": "1HAjPz_R33AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AFTER EXTRACTION FEATURE\n",
        "datas = pd.read_csv(\"drive/My Drive/Dann Dataset/PIR last 30 list dataset train.csv\", sep=';', header=0)\n",
        "print(datas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFwfBHq18vW",
        "outputId": "a341e535-4150-4bd1-d0c9-4e5002cfa0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Durasi1,Data1|Pir1,Data1|Pir2,Data1|Pir3,Data1|Pir4,Durasi2,Data2|Pir1,Data2|Pir2,Data2|Pir3,Data2|Pir4,Durasi3,Data3|Pir1,Data3|Pir2,Data3|Pir3,Data3|Pir4,Durasi4,Data4|Pir1,Data4|Pir2,Data4|Pir3,Data4|Pir4,Durasi5,Data5|Pir1,Data5|Pir2,Data5|Pir3,Data5|Pir4,Durasi6,Data6|Pir1,Data6|Pir2,Data6|Pir3,Data6|Pir4,Durasi7,Data7|Pir1,Data7|Pir2,Data7|Pir3,Data7|Pir4,Durasi8,Data8|Pir1,Data8|Pir2,Data8|Pir3,Data8|Pir4,Durasi9,Data9|Pir1,Data9|Pir2,Data9|Pir3,Data9|Pir4,Durasi10,Data10|Pir1,Data10|Pir2,Data10|Pir3,Data10|Pir4,Durasi11,Data11|Pir1,Data11|Pir2,Data11|Pir3,Data11|Pir4,Durasi12,Data12|Pir1,Data12|Pir2,Data12|Pir3,Data12|Pir4,Durasi13,Data13|Pir1,Data13|Pir2,Data13|Pir3,Data13|Pir4,Durasi14,Data14|Pir1,Data14|Pir2,Data14|Pir3,Data14|Pir4,Durasi15,Data15|Pir1,Data15|Pir2,Data15|Pir3,Data15|Pir4,Durasi16,Data16|Pir1,Data16|Pir2,Data16|Pir3,Data16|Pir4,Durasi17,Data17|Pir1,Data17|Pir2,Data17|Pir3,Data17|Pir4,Durasi18,Data18|Pir1,Data18|Pir2,Data18|Pir3,Data18|Pir4,Durasi19,Data19|Pir1,Data19|Pir2,Data19|Pir3,Data19|Pir4,Durasi20,Data20|Pir1,Data20|Pir2,Data20|Pir3,Data20|Pir4,Durasi21,Data21|Pir1,Data21|Pir2,Data21|Pir3,Data21|Pir4,Durasi22,Data22|Pir1,Data22|Pir2,Data22|Pir3,Data22|Pir4,Durasi23,Data23|Pir1,Data23|Pir2,Data23|Pir3,Data23|Pir4,Durasi24,Data24|Pir1,Data24|Pir2,Data24|Pir3,Data24|Pir4,Durasi25,Data25|Pir1,Data25|Pir2,Data25|Pir3,Data25|Pir4,Durasi26,Data26|Pir1,Data26|Pir2,Data26|Pir3,Data26|Pir4,Durasi27,Data27|Pir1,Data27|Pir2,Data27|Pir3,Data27|Pir4,Durasi28,Data28|Pir1,Data28|Pir2,Data28|Pir3,Data28|Pir4,Durasi29,Data29|Pir1,Data29|Pir2,Data29|Pir3,Data29|Pir4,Durasi30,Data30|Pir1,Data30|Pir2,Data30|Pir3,Data30|Pir4,Gerakan\n",
            "0       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "1       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "2       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "3       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "4       0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "...                                                   ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "200284  5,0,0,0,1,1,0,1,0,0,1,1,0,0,0,1,0,0,0,0,2,1,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "200285  1,0,1,0,0,1,1,0,0,0,1,0,0,0,0,2,1,0,0,0,1,0,1,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "200286  1,1,0,0,0,1,0,0,0,0,2,1,0,0,0,1,0,1,0,0,1,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "200287  1,0,0,0,0,2,1,0,0,0,1,0,1,0,0,1,0,0,0,1,1,0,1,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "200288  2,1,0,0,0,1,0,1,0,0,1,0,0,0,1,1,0,1,0,0,2,0,0,...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "\n",
            "[200289 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWQsUdja77bD"
      },
      "outputs": [],
      "source": [
        "# LOAD DATASET\n",
        "feature_data =pd.read_csv(\"drive/MyDrive/Dann Dataset/PIR last 30 list dataset train.csv\")\n",
        "\n",
        "# ADD LABEL ENCODER\n",
        "label_encoder = LabelEncoder()\n",
        "feature_data['Gerakan'] = label_encoder.fit_transform(feature_data['Gerakan'])\n",
        "datas_labels = label_encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDaHAU7eD4CR",
        "outputId": "e5f0cfd2-d3a9-42ef-aebd-455f795fc75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LOITERING' 'NORMAL']\n"
          ]
        }
      ],
      "source": [
        "# LIST OF LABELS\n",
        "print(datas_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEc59ruoD6MC",
        "outputId": "ba82e014-3691-41f9-af35-6717ca11ed64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (140202, 30, 5) (140202, 1)\n",
            "Test: (60087, 30, 5) (60087, 1)\n"
          ]
        }
      ],
      "source": [
        "x = feature_data.drop('Gerakan',axis=1)\n",
        "y = feature_data['Gerakan']\n",
        "\n",
        "# RESHAPE DATASET\n",
        "x = x.values.reshape(-1,30,5)   #INPUT 4\n",
        "y = y.values.reshape((-1,1))\n",
        "\n",
        "# SPLIT DATASET\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) #Split Dataset Train 70% dan Test 30%\n",
        "\n",
        "# CHECK THE SHAPE\n",
        "print(\"Train:\", x_train.shape , y_train.shape)\n",
        "print(\"Test:\",x_test.shape , y_test.shape)\n",
        "\n",
        "# SET TOTAL FOLD\n",
        "total_fold = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a4z8GH7_qgA",
        "outputId": "b5e7cb91-57f2-475a-b31c-fa5b398156c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6899 - accuracy: 0.5538 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.6212 - accuracy: 0.6593 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.5638 - accuracy: 0.7046 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.5219 - accuracy: 0.7327 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.4455 - accuracy: 0.7994 - 34s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3406 - accuracy: 0.8649 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2705 - accuracy: 0.8980 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2274 - accuracy: 0.9158 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.2015 - accuracy: 0.9262 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1800 - accuracy: 0.9342 - 32s/epoch - 29ms/step\n",
            "accuracy: 93.97%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6630 - accuracy: 0.6039 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.5908 - accuracy: 0.6727 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 34s - loss: 0.5418 - accuracy: 0.7169 - 34s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4706 - accuracy: 0.7787 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3756 - accuracy: 0.8439 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3014 - accuracy: 0.8834 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2508 - accuracy: 0.9084 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2174 - accuracy: 0.9223 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1942 - accuracy: 0.9308 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1806 - accuracy: 0.9348 - 32s/epoch - 29ms/step\n",
            "accuracy: 94.49%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6709 - accuracy: 0.5779 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 34s - loss: 0.5954 - accuracy: 0.6708 - 34s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.5254 - accuracy: 0.7317 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4293 - accuracy: 0.8070 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3463 - accuracy: 0.8575 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.2899 - accuracy: 0.8870 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2469 - accuracy: 0.9064 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2113 - accuracy: 0.9210 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1836 - accuracy: 0.9318 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 34s - loss: 0.1669 - accuracy: 0.9375 - 34s/epoch - 30ms/step\n",
            "accuracy: 92.52%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.6997 - accuracy: 0.5573 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 32s - loss: 0.5918 - accuracy: 0.6722 - 32s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.5351 - accuracy: 0.7195 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.4769 - accuracy: 0.7723 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 32s - loss: 0.3820 - accuracy: 0.8423 - 32s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 32s - loss: 0.3132 - accuracy: 0.8768 - 32s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.2652 - accuracy: 0.8988 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 34s - loss: 0.2255 - accuracy: 0.9159 - 34s/epoch - 30ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.1987 - accuracy: 0.9266 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.1801 - accuracy: 0.9334 - 32s/epoch - 29ms/step\n",
            "accuracy: 93.16%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.7001 - accuracy: 0.5429 - 34s/epoch - 30ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 32s - loss: 0.6473 - accuracy: 0.6132 - 32s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.6020 - accuracy: 0.6686 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 32s - loss: 0.5624 - accuracy: 0.7003 - 32s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.5179 - accuracy: 0.7380 - 34s/epoch - 31ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.4337 - accuracy: 0.8112 - 33s/epoch - 30ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 32s - loss: 0.3230 - accuracy: 0.8783 - 32s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 32s - loss: 0.2622 - accuracy: 0.9038 - 32s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 32s - loss: 0.2248 - accuracy: 0.9178 - 32s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 32s - loss: 0.2006 - accuracy: 0.9267 - 32s/epoch - 29ms/step\n",
            "accuracy: 91.49%\n",
            "Model Accuracy List:  [93.97311210632324, 94.49021220207214, 92.52139925956726, 93.1562066078186, 91.48716330528259]\n",
            "93.13% (+/- 1.06%)\n"
          ]
        }
      ],
      "source": [
        "#RNN BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4), #metode optimizer default\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK7jRvXLFQMh",
        "outputId": "f627f092-3b8e-482b-938e-e611b314a073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 36s - loss: 0.1879 - accuracy: 0.9173 - 36s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0607 - accuracy: 0.9769 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0375 - accuracy: 0.9857 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0326 - accuracy: 0.9870 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0579 - accuracy: 0.9814 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 35s - loss: 0.0320 - accuracy: 0.9877 - 35s/epoch - 31ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 35s - loss: 0.0229 - accuracy: 0.9909 - 35s/epoch - 31ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0221 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0223 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0240 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.44%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.1944 - accuracy: 0.9121 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0534 - accuracy: 0.9799 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 34s - loss: 0.0375 - accuracy: 0.9854 - 34s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 34s - loss: 0.0293 - accuracy: 0.9881 - 34s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0281 - accuracy: 0.9887 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0246 - accuracy: 0.9898 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0226 - accuracy: 0.9908 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0213 - accuracy: 0.9914 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0232 - accuracy: 0.9910 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0161 - accuracy: 0.9932 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.42%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 36s - loss: 0.1704 - accuracy: 0.9220 - 36s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0508 - accuracy: 0.9807 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 32s - loss: 0.0350 - accuracy: 0.9865 - 32s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0395 - accuracy: 0.9854 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0243 - accuracy: 0.9904 - 33s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0257 - accuracy: 0.9896 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0266 - accuracy: 0.9896 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 34s - loss: 0.0205 - accuracy: 0.9919 - 34s/epoch - 31ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0219 - accuracy: 0.9912 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0205 - accuracy: 0.9913 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.10%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.1727 - accuracy: 0.9257 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 33s - loss: 0.0643 - accuracy: 0.9763 - 33s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0462 - accuracy: 0.9822 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0328 - accuracy: 0.9870 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 34s - loss: 0.0301 - accuracy: 0.9879 - 34s/epoch - 31ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0273 - accuracy: 0.9890 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0247 - accuracy: 0.9900 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0242 - accuracy: 0.9901 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0194 - accuracy: 0.9923 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 33s - loss: 0.0179 - accuracy: 0.9928 - 33s/epoch - 29ms/step\n",
            "accuracy: 99.24%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1122/1122 - 34s - loss: 0.2104 - accuracy: 0.9060 - 34s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 34s - loss: 0.0566 - accuracy: 0.9788 - 34s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 33s - loss: 0.0379 - accuracy: 0.9856 - 33s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 33s - loss: 0.0406 - accuracy: 0.9849 - 33s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 33s - loss: 0.0305 - accuracy: 0.9877 - 33s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 33s - loss: 0.0258 - accuracy: 0.9897 - 33s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 33s - loss: 0.0202 - accuracy: 0.9920 - 33s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 33s - loss: 0.0227 - accuracy: 0.9910 - 33s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 33s - loss: 0.0199 - accuracy: 0.9914 - 33s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 34s - loss: 0.0189 - accuracy: 0.9925 - 34s/epoch - 30ms/step\n",
            "accuracy: 99.59%\n",
            "Model Accuracy List:  [99.4365394115448, 99.41514134407043, 99.09771680831909, 99.23680424690247, 99.58987236022949]\n",
            "99.36% (+/- 0.17%)\n"
          ]
        }
      ],
      "source": [
        "#RNN AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9kIya-tb_Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f9ab48-67a1-4316-fb21-9b3e372afe83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1122/1122 - 158s - loss: 0.6897 - accuracy: 0.5373 - 158s/epoch - 141ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 131s - loss: 0.6679 - accuracy: 0.5809 - 131s/epoch - 117ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6613 - accuracy: 0.6095 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.6561 - accuracy: 0.6216 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6515 - accuracy: 0.6264 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 116s - loss: 0.6474 - accuracy: 0.6294 - 116s/epoch - 103ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 114s - loss: 0.6435 - accuracy: 0.6315 - 114s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6398 - accuracy: 0.6341 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6362 - accuracy: 0.6367 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.6326 - accuracy: 0.6394 - 116s/epoch - 104ms/step\n",
            "accuracy: 63.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.6881 - accuracy: 0.5133 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 114s - loss: 0.6755 - accuracy: 0.5149 - 114s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6673 - accuracy: 0.5721 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 115s - loss: 0.6607 - accuracy: 0.6107 - 115s/epoch - 103ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.6551 - accuracy: 0.6215 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.6502 - accuracy: 0.6273 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6458 - accuracy: 0.6300 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6415 - accuracy: 0.6322 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6375 - accuracy: 0.6347 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.6335 - accuracy: 0.6367 - 116s/epoch - 103ms/step\n",
            "accuracy: 63.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.6894 - accuracy: 0.5385 - 117s/epoch - 104ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 115s - loss: 0.6770 - accuracy: 0.5655 - 115s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6691 - accuracy: 0.5985 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 113s - loss: 0.6623 - accuracy: 0.6130 - 113s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6578 - accuracy: 0.6180 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.6536 - accuracy: 0.6206 - 114s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6497 - accuracy: 0.6251 - 117s/epoch - 105ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.6458 - accuracy: 0.6281 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 114s - loss: 0.6420 - accuracy: 0.6314 - 114s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 117s - loss: 0.6383 - accuracy: 0.6347 - 117s/epoch - 104ms/step\n",
            "accuracy: 63.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.6908 - accuracy: 0.5096 - 117s/epoch - 104ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.6762 - accuracy: 0.5405 - 116s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.6682 - accuracy: 0.5808 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 115s - loss: 0.6615 - accuracy: 0.6097 - 115s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.6559 - accuracy: 0.6161 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 115s - loss: 0.6510 - accuracy: 0.6215 - 115s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.6465 - accuracy: 0.6247 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.6421 - accuracy: 0.6277 - 114s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.6380 - accuracy: 0.6308 - 116s/epoch - 103ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 113s - loss: 0.6341 - accuracy: 0.6331 - 113s/epoch - 101ms/step\n",
            "accuracy: 63.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_9_layer_call_fn, gru_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.6846 - accuracy: 0.5129 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.6721 - accuracy: 0.5434 - 116s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 114s - loss: 0.6648 - accuracy: 0.5658 - 114s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.6591 - accuracy: 0.5809 - 116s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 114s - loss: 0.6541 - accuracy: 0.5917 - 114s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 116s - loss: 0.6496 - accuracy: 0.5992 - 116s/epoch - 104ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 116s - loss: 0.6456 - accuracy: 0.6060 - 116s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.6417 - accuracy: 0.6120 - 114s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.6381 - accuracy: 0.6175 - 116s/epoch - 103ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 114s - loss: 0.6344 - accuracy: 0.6211 - 114s/epoch - 101ms/step\n",
            "accuracy: 62.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [63.84579539299011, 63.92781734466553, 63.291728496551514, 63.40941786766052, 62.767475843429565]\n",
            "63.45% (+/- 0.42%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#GRU BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2opkRY-NnnGE",
        "outputId": "d81c9be2-97a0-4a1f-a2c8-2073c1c47234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 119s - loss: 0.1998 - accuracy: 0.9084 - 119s/epoch - 106ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 117s - loss: 0.0614 - accuracy: 0.9747 - 117s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 114s - loss: 0.0339 - accuracy: 0.9871 - 114s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 117s - loss: 0.1209 - accuracy: 0.9736 - 117s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 117s - loss: 0.0238 - accuracy: 0.9911 - 117s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.0193 - accuracy: 0.9927 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.0146 - accuracy: 0.9947 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 115s - loss: 0.0141 - accuracy: 0.9946 - 115s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 117s - loss: 0.0139 - accuracy: 0.9946 - 117s/epoch - 104ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.0122 - accuracy: 0.9955 - 116s/epoch - 103ms/step\n",
            "accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 117s - loss: 0.2022 - accuracy: 0.9043 - 117s/epoch - 105ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0523 - accuracy: 0.9788 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 116s - loss: 0.0310 - accuracy: 0.9878 - 116s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.0225 - accuracy: 0.9909 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.0185 - accuracy: 0.9923 - 116s/epoch - 104ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 114s - loss: 0.0183 - accuracy: 0.9927 - 114s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 117s - loss: 0.0155 - accuracy: 0.9935 - 117s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 117s - loss: 0.0140 - accuracy: 0.9945 - 117s/epoch - 104ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 115s - loss: 0.0145 - accuracy: 0.9945 - 115s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 118s - loss: 0.0116 - accuracy: 0.9956 - 118s/epoch - 105ms/step\n",
            "accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 120s - loss: 0.1896 - accuracy: 0.9134 - 120s/epoch - 107ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 114s - loss: 0.0560 - accuracy: 0.9769 - 114s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 117s - loss: 0.0357 - accuracy: 0.9867 - 117s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.0248 - accuracy: 0.9902 - 116s/epoch - 104ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 114s - loss: 0.0198 - accuracy: 0.9919 - 114s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 117s - loss: 0.0158 - accuracy: 0.9936 - 117s/epoch - 104ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 116s - loss: 0.0289 - accuracy: 0.9918 - 116s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.0115 - accuracy: 0.9954 - 114s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 116s - loss: 0.0115 - accuracy: 0.9953 - 116s/epoch - 104ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 114s - loss: 0.0130 - accuracy: 0.9948 - 114s/epoch - 102ms/step\n",
            "accuracy: 98.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_16_layer_call_fn, gru_cell_16_layer_call_and_return_conditional_losses, gru_cell_17_layer_call_fn, gru_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 118s - loss: 0.2009 - accuracy: 0.9087 - 118s/epoch - 105ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0553 - accuracy: 0.9775 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 116s - loss: 0.0317 - accuracy: 0.9880 - 116s/epoch - 103ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 114s - loss: 0.0223 - accuracy: 0.9914 - 114s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 116s - loss: 0.6613 - accuracy: 0.8001 - 116s/epoch - 103ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 113s - loss: 0.1165 - accuracy: 0.9584 - 113s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 115s - loss: 0.0547 - accuracy: 0.9802 - 115s/epoch - 103ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 115s - loss: 0.0394 - accuracy: 0.9854 - 115s/epoch - 103ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 113s - loss: 0.0300 - accuracy: 0.9887 - 113s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 116s - loss: 0.0250 - accuracy: 0.9903 - 116s/epoch - 103ms/step\n",
            "accuracy: 98.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_18_layer_call_fn, gru_cell_18_layer_call_and_return_conditional_losses, gru_cell_19_layer_call_fn, gru_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 119s - loss: 0.2170 - accuracy: 0.8975 - 119s/epoch - 106ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 116s - loss: 0.0553 - accuracy: 0.9775 - 116s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 113s - loss: 0.0344 - accuracy: 0.9871 - 113s/epoch - 100ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 116s - loss: 0.0234 - accuracy: 0.9906 - 116s/epoch - 103ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 115s - loss: 0.0185 - accuracy: 0.9926 - 115s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 113s - loss: 0.0252 - accuracy: 0.9918 - 113s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 115s - loss: 0.0152 - accuracy: 0.9938 - 115s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 114s - loss: 0.0141 - accuracy: 0.9944 - 114s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 113s - loss: 0.0137 - accuracy: 0.9945 - 113s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 115s - loss: 0.0119 - accuracy: 0.9953 - 115s/epoch - 102ms/step\n",
            "accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [99.5756208896637, 99.33668375015259, 98.76961708068848, 98.98002743721008, 99.33309555053711]\n",
            "99.20% (+/- 0.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#GRU AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzMQ1Rf4n9qQ",
        "outputId": "1d0fc74f-c4c6-40c4-b56e-68767478b6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 126s - loss: 0.6782 - accuracy: 0.5242 - 126s/epoch - 112ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6670 - accuracy: 0.6303 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 124s - loss: 0.6571 - accuracy: 0.6869 - 124s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6471 - accuracy: 0.6965 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.6366 - accuracy: 0.6991 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 122s - loss: 0.6260 - accuracy: 0.7011 - 122s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6154 - accuracy: 0.7016 - 125s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.6049 - accuracy: 0.7014 - 125s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.5950 - accuracy: 0.7005 - 125s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.5862 - accuracy: 0.6995 - 124s/epoch - 111ms/step\n",
            "accuracy: 70.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.6997 - accuracy: 0.4280 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6884 - accuracy: 0.4960 - 124s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6791 - accuracy: 0.5184 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6691 - accuracy: 0.5883 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.6591 - accuracy: 0.6584 - 125s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6503 - accuracy: 0.6852 - 125s/epoch - 112ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 126s - loss: 0.6413 - accuracy: 0.6920 - 126s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 123s - loss: 0.6319 - accuracy: 0.6962 - 123s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.6221 - accuracy: 0.6993 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.6121 - accuracy: 0.7000 - 125s/epoch - 112ms/step\n",
            "accuracy: 69.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.6864 - accuracy: 0.5072 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6763 - accuracy: 0.5973 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6657 - accuracy: 0.6623 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.6570 - accuracy: 0.6914 - 125s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 123s - loss: 0.6483 - accuracy: 0.6968 - 123s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6389 - accuracy: 0.6995 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.6291 - accuracy: 0.7010 - 124s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.6189 - accuracy: 0.7016 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.6089 - accuracy: 0.7020 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.5992 - accuracy: 0.7014 - 124s/epoch - 111ms/step\n",
            "accuracy: 69.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.6917 - accuracy: 0.5785 - 127s/epoch - 113ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 124s - loss: 0.6768 - accuracy: 0.6708 - 124s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6669 - accuracy: 0.6979 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 123s - loss: 0.6571 - accuracy: 0.7016 - 123s/epoch - 110ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 126s - loss: 0.6469 - accuracy: 0.7022 - 126s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.6360 - accuracy: 0.7031 - 125s/epoch - 112ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6248 - accuracy: 0.7016 - 125s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.6135 - accuracy: 0.7012 - 125s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.6026 - accuracy: 0.6996 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.5927 - accuracy: 0.6977 - 125s/epoch - 111ms/step\n",
            "accuracy: 69.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.6843 - accuracy: 0.5172 - 127s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.6688 - accuracy: 0.6362 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.6575 - accuracy: 0.6814 - 125s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 126s - loss: 0.6467 - accuracy: 0.6913 - 126s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 123s - loss: 0.6359 - accuracy: 0.6960 - 123s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 124s - loss: 0.6246 - accuracy: 0.6989 - 124s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.6127 - accuracy: 0.7009 - 125s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.6017 - accuracy: 0.7015 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 126s - loss: 0.5919 - accuracy: 0.7019 - 126s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.5834 - accuracy: 0.7010 - 125s/epoch - 111ms/step\n",
            "accuracy: 70.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [70.0082004070282, 69.80849504470825, 69.86448168754578, 69.57560777664185, 70.44935822486877]\n",
            "69.94% (+/- 0.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#LSTM BEFORE TUNING \n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqJ27C2noahB",
        "outputId": "d209d1f3-a54f-4634-c07e-d0f49848194f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 127s - loss: 0.2203 - accuracy: 0.9027 - 127s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0972 - accuracy: 0.9645 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0531 - accuracy: 0.9795 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0409 - accuracy: 0.9837 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.0298 - accuracy: 0.9881 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0297 - accuracy: 0.9890 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.0232 - accuracy: 0.9906 - 124s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0198 - accuracy: 0.9915 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0179 - accuracy: 0.9928 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0178 - accuracy: 0.9927 - 125s/epoch - 111ms/step\n",
            "accuracy: 98.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.2340 - accuracy: 0.8967 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0835 - accuracy: 0.9667 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0727 - accuracy: 0.9729 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0454 - accuracy: 0.9824 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 124s - loss: 0.0334 - accuracy: 0.9869 - 124s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 124s - loss: 0.0366 - accuracy: 0.9868 - 124s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 125s - loss: 0.0246 - accuracy: 0.9903 - 125s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0285 - accuracy: 0.9892 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 124s - loss: 0.0186 - accuracy: 0.9923 - 124s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0189 - accuracy: 0.9920 - 125s/epoch - 111ms/step\n",
            "accuracy: 98.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 128s - loss: 0.2444 - accuracy: 0.8944 - 128s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0871 - accuracy: 0.9653 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0551 - accuracy: 0.9787 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 126s - loss: 0.0393 - accuracy: 0.9845 - 126s/epoch - 112ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 126s - loss: 0.0307 - accuracy: 0.9878 - 126s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0282 - accuracy: 0.9889 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 126s - loss: 0.0221 - accuracy: 0.9910 - 126s/epoch - 112ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 126s - loss: 0.0216 - accuracy: 0.9916 - 126s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0171 - accuracy: 0.9931 - 125s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 125s - loss: 0.0185 - accuracy: 0.9923 - 125s/epoch - 112ms/step\n",
            "accuracy: 98.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 128s - loss: 0.2332 - accuracy: 0.8966 - 128s/epoch - 114ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.1086 - accuracy: 0.9583 - 125s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 124s - loss: 0.0581 - accuracy: 0.9771 - 124s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 124s - loss: 0.0612 - accuracy: 0.9797 - 124s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 125s - loss: 0.0337 - accuracy: 0.9872 - 125s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 125s - loss: 0.0280 - accuracy: 0.9890 - 125s/epoch - 111ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 124s - loss: 0.0249 - accuracy: 0.9902 - 124s/epoch - 111ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 124s - loss: 0.0233 - accuracy: 0.9905 - 124s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 125s - loss: 0.0243 - accuracy: 0.9902 - 125s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 124s - loss: 0.0192 - accuracy: 0.9922 - 124s/epoch - 111ms/step\n",
            "accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1122/1122 - 129s - loss: 0.2265 - accuracy: 0.9012 - 129s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "1122/1122 - 125s - loss: 0.0805 - accuracy: 0.9678 - 125s/epoch - 112ms/step\n",
            "Epoch 3/10\n",
            "1122/1122 - 125s - loss: 0.0721 - accuracy: 0.9748 - 125s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "1122/1122 - 125s - loss: 0.0442 - accuracy: 0.9833 - 125s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "1122/1122 - 127s - loss: 0.0347 - accuracy: 0.9868 - 127s/epoch - 113ms/step\n",
            "Epoch 6/10\n",
            "1122/1122 - 127s - loss: 0.0276 - accuracy: 0.9893 - 127s/epoch - 113ms/step\n",
            "Epoch 7/10\n",
            "1122/1122 - 123s - loss: 0.0212 - accuracy: 0.9913 - 123s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "1122/1122 - 125s - loss: 0.0243 - accuracy: 0.9905 - 125s/epoch - 112ms/step\n",
            "Epoch 9/10\n",
            "1122/1122 - 126s - loss: 0.0160 - accuracy: 0.9936 - 126s/epoch - 113ms/step\n",
            "Epoch 10/10\n",
            "1122/1122 - 126s - loss: 0.0187 - accuracy: 0.9928 - 126s/epoch - 112ms/step\n",
            "accuracy: 99.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [98.38094115257263, 98.70190024375916, 98.84807467460632, 99.4436502456665, 99.08345341682434]\n",
            "98.89% (+/- 0.36%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#LSTM AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):                                     \n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning_fold_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxWL8XMMQBP"
      },
      "source": [
        "Get list of accuracy, precision, recall and f1\n",
        "Pengujian Data Testing\n",
        "- Load Model untuk klasifikasi data Testing\n",
        "- Model sudah di Load lalu melakukan Predict terhadap data Testing\n",
        "- Simpan data Hasil Predict untuk codingan selanjutnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bz3MmtKu0Rz",
        "outputId": "3f42541d-4a61-4179-e5d6-14233032d95e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 15s 8ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 14s 7ms/step\n",
            "1878/1878 [==============================] - 28s 15ms/step\n",
            "1878/1878 [==============================] - 28s 14ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 28s 14ms/step\n",
            "1878/1878 [==============================] - 29s 15ms/step\n",
            "1878/1878 [==============================] - 27s 14ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n"
          ]
        }
      ],
      "source": [
        "#RNN K-FOLD BEFORE TUNING \n",
        "file_rnn_fold_before = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_before = [(pickle.load(open(file_rnn_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_before = [(loaded_model_rnn_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_before = [(np.argmax(y_pred_rnn_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_before[ypvc] = np.reshape(y_pred_values_rnn_before[ypvc],(-1,1))\n",
        "result_rnn_before = [(classification_report(y_test, y_pred_values_rnn_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#RNN K-FOLD AFTER TUNING \n",
        "file_rnn_fold_after = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_after = [(pickle.load(open(file_rnn_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_after = [(loaded_model_rnn_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_after = [(np.argmax(y_pred_rnn_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_after[ypvc] = np.reshape(y_pred_values_rnn_after[ypvc],(-1,1))\n",
        "result_rnn_after = [(classification_report(y_test, y_pred_values_rnn_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU K-FOLD BEFORE TUNING\n",
        "file_gru_fold_before = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_before = [(pickle.load(open(file_gru_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_before = [(loaded_model_gru_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_before = [(np.argmax(y_pred_gru_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_before[ypvc] = np.reshape(y_pred_values_gru_before[ypvc],(-1,1))\n",
        "result_gru_before = [(classification_report(y_test, y_pred_values_gru_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU K-FOLD AFTER TUNING\n",
        "file_gru_fold_after = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_after = [(pickle.load(open(file_gru_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_after = [(loaded_model_gru_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_after = [(np.argmax(y_pred_gru_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_after[ypvc] = np.reshape(y_pred_values_gru_after[ypvc],(-1,1))\n",
        "result_gru_after = [(classification_report(y_test, y_pred_values_gru_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM K-FOLD BEFORE TUNING\n",
        "file_lstm_fold_before = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_before_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_before = [(pickle.load(open(file_lstm_fold_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_before = [(loaded_model_lstm_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_before = [(np.argmax(y_pred_lstm_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_before[ypvc] = np.reshape(y_pred_values_lstm_before[ypvc],(-1,1))\n",
        "result_lstm_before = [(classification_report(y_test, y_pred_values_lstm_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM K-FOLD AFTER TUNING\n",
        "file_lstm_fold_after = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_after_tuning_fold_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_after = [(pickle.load(open(file_lstm_fold_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_after = [(loaded_model_lstm_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_after = [(np.argmax(y_pred_lstm_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_after[ypvc] = np.reshape(y_pred_values_lstm_after[ypvc],(-1,1))\n",
        "result_lstm_after = [(classification_report(y_test, y_pred_values_lstm_after[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4NUtnXXOStu"
      },
      "source": [
        "Buat List untuk menampung dari Hasil dari Fold untuk Precision,Recall,Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64u5UGcxHJF"
      },
      "outputs": [],
      "source": [
        "precision_list_before = {}\n",
        "precision_list_after = {}\n",
        "recall_list_before = {}\n",
        "recall_list_after = {}\n",
        "accuracy_list_before = {}\n",
        "accuracy_list_after = {}\n",
        "f1_list_before = {}\n",
        "f1_list_after = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8SnDZvIN6zp"
      },
      "source": [
        "Rata-rata dari Precision,Recall,F1-Score,Accuracy\n",
        "\n",
        "Mengambil data hasil predict pada codingan sebelumnya\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T36Kk96Lu-MY"
      },
      "outputs": [],
      "source": [
        "for sco in range(total_fold):\n",
        "  precision_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['precision'] , result_gru_before[sco]['weighted avg']['precision'], result_lstm_before[sco]['weighted avg']['precision']]\n",
        "  precision_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['precision'] , result_gru_after[sco]['weighted avg']['precision'], result_lstm_after[sco]['weighted avg']['precision']]\n",
        "  recall_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['recall'] , result_gru_before[sco]['weighted avg']['recall'], result_lstm_before[sco]['weighted avg']['recall']]\n",
        "  recall_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['recall'] , result_gru_after[sco]['weighted avg']['recall'], result_lstm_after[sco]['weighted avg']['recall']]\n",
        "  f1_list_before[(sco+1)] = [result_rnn_before[sco]['weighted avg']['f1-score'] , result_gru_before[sco]['weighted avg']['f1-score'], result_lstm_before[sco]['weighted avg']['f1-score']]\n",
        "  f1_list_after[(sco+1)] = [result_rnn_after[sco]['weighted avg']['f1-score'] , result_gru_after[sco]['weighted avg']['f1-score'], result_lstm_after[sco]['weighted avg']['f1-score']]\n",
        "  accuracy_list_before[(sco+1)] = [result_rnn_before[sco]['accuracy'] , result_gru_before[sco]['accuracy'], result_lstm_before[sco]['accuracy']]\n",
        "  accuracy_list_after[(sco+1)] = [result_rnn_after[sco]['accuracy'] , result_gru_after[sco]['accuracy'], result_lstm_after[sco]['accuracy']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY3txyT23pYf"
      },
      "source": [
        "Menampilkan Hasil Predict Tiap Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKzWuXez4jKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e428ce68-b0a7-4b6d-8f6d-8672153d3d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Precision K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.943           0.695      0.734     \n",
            "2        0.944           0.728      0.747     \n",
            "3        0.929           0.718      0.745     \n",
            "4        0.938           0.710      0.731     \n",
            "5        0.924           0.679      0.744     \n",
            "\n",
            "\n",
            "      Precision K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.986     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.989      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      Recall K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.639      0.697     \n",
            "2        0.943           0.636      0.699     \n",
            "3        0.925           0.633      0.700     \n",
            "4        0.932           0.635      0.696     \n",
            "5        0.915           0.624      0.701     \n",
            "\n",
            "\n",
            "      Recall K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.639      0.697     \n",
            "2        0.943           0.636      0.699     \n",
            "3        0.925           0.633      0.700     \n",
            "4        0.932           0.635      0.696     \n",
            "5        0.915           0.624      0.701     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold Sebelum Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.941           0.615      0.687     \n",
            "2        0.943           0.600      0.686     \n",
            "3        0.924           0.597      0.687     \n",
            "4        0.932           0.603      0.686     \n",
            "5        0.914           0.597      0.689     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold Sesudah Tuning\n",
            "Fold     RNN             GRU        LSTM      \n",
            "1        0.995           0.995      0.985     \n",
            "2        0.995           0.994      0.988     \n",
            "3        0.991           0.988      0.988     \n",
            "4        0.993           0.989      0.995     \n",
            "5        0.997           0.993      0.990     \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_before.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_after.items():\n",
        "    rnn_fold_data, gru_fold_data, lstm_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(rnn_fold_data,\".3f\"), format(gru_fold_data,\".3f\"), format(lstm_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA TESTING BEFORE & AFTER TUNING 30%"
      ],
      "metadata": {
        "id": "TMmZTwqDV2QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN 30% DATA BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_fold_before_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_before.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OphqT1cKYiwX",
        "outputId": "48e86355-0df4-4b36-e3ac-e618c82cc667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 15s - loss: 0.6898 - accuracy: 0.5532 - 15s/epoch - 31ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.6451 - accuracy: 0.6154 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.6134 - accuracy: 0.6538 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.5861 - accuracy: 0.6809 - 14s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.5612 - accuracy: 0.7030 - 14s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.5313 - accuracy: 0.7322 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.4851 - accuracy: 0.7762 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.4194 - accuracy: 0.8268 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.3614 - accuracy: 0.8595 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.3256 - accuracy: 0.8733 - 14s/epoch - 29ms/step\n",
            "accuracy: 89.95%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 15s - loss: 0.7050 - accuracy: 0.5402 - 15s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.6649 - accuracy: 0.5901 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.6378 - accuracy: 0.6349 - 14s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 15s - loss: 0.6126 - accuracy: 0.6676 - 15s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.5860 - accuracy: 0.6898 - 14s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.5598 - accuracy: 0.7108 - 14s/epoch - 30ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.5321 - accuracy: 0.7345 - 14s/epoch - 30ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.4971 - accuracy: 0.7653 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.4491 - accuracy: 0.8047 - 14s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.3891 - accuracy: 0.8430 - 14s/epoch - 29ms/step\n",
            "accuracy: 86.49%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 16s - loss: 0.6872 - accuracy: 0.5562 - 16s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.6490 - accuracy: 0.6125 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.6181 - accuracy: 0.6570 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.5908 - accuracy: 0.6845 - 14s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.5685 - accuracy: 0.7004 - 14s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.5494 - accuracy: 0.7157 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.5290 - accuracy: 0.7326 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.5035 - accuracy: 0.7552 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.4670 - accuracy: 0.7836 - 14s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.4174 - accuracy: 0.8189 - 14s/epoch - 30ms/step\n",
            "accuracy: 84.52%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 15s - loss: 0.6799 - accuracy: 0.5653 - 15s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.6468 - accuracy: 0.6126 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.6198 - accuracy: 0.6486 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.5900 - accuracy: 0.6804 - 14s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.5586 - accuracy: 0.7053 - 14s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.5299 - accuracy: 0.7263 - 14s/epoch - 30ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.4994 - accuracy: 0.7544 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.4629 - accuracy: 0.7871 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.4143 - accuracy: 0.8263 - 14s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.3693 - accuracy: 0.8521 - 14s/epoch - 29ms/step\n",
            "accuracy: 84.83%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 15s - loss: 0.7431 - accuracy: 0.4914 - 15s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.6996 - accuracy: 0.5307 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.6716 - accuracy: 0.5703 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.6471 - accuracy: 0.6042 - 14s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.6243 - accuracy: 0.6335 - 14s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.6028 - accuracy: 0.6573 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.5826 - accuracy: 0.6781 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.5648 - accuracy: 0.6932 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.5488 - accuracy: 0.7063 - 14s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.5324 - accuracy: 0.7196 - 14s/epoch - 29ms/step\n",
            "accuracy: 72.89%\n",
            "Model Accuracy List:  [89.94840979576111, 86.48693561553955, 84.52192544937134, 84.82982516288757, 72.88841009140015]\n",
            "83.74% (+/- 5.76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN 30% DATA AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.SimpleRNN(100, return_sequences=True, activation='tanh'),\n",
        "            layers.SimpleRNN(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_fold_after_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_after.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLd4fA5_rehK",
        "outputId": "5fd81576-c28d-43ee-9c6c-0da2faa0a842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 17s - loss: 0.4240 - accuracy: 0.7843 - 17s/epoch - 35ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.1158 - accuracy: 0.9563 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.0732 - accuracy: 0.9716 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.0491 - accuracy: 0.9816 - 14s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.0437 - accuracy: 0.9839 - 14s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.0311 - accuracy: 0.9878 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.0317 - accuracy: 0.9880 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.0551 - accuracy: 0.9810 - 14s/epoch - 30ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.0279 - accuracy: 0.9889 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.0222 - accuracy: 0.9913 - 14s/epoch - 30ms/step\n",
            "accuracy: 96.95%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 16s - loss: 0.2782 - accuracy: 0.8691 - 16s/epoch - 33ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.0992 - accuracy: 0.9626 - 14s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.0706 - accuracy: 0.9742 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.0629 - accuracy: 0.9777 - 14s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.0467 - accuracy: 0.9822 - 14s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.0413 - accuracy: 0.9843 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.0336 - accuracy: 0.9870 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.0305 - accuracy: 0.9886 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.0583 - accuracy: 0.9805 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.0278 - accuracy: 0.9891 - 14s/epoch - 30ms/step\n",
            "accuracy: 97.33%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 16s - loss: 0.3092 - accuracy: 0.8540 - 16s/epoch - 33ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.0883 - accuracy: 0.9662 - 14s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.0554 - accuracy: 0.9799 - 14s/epoch - 30ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.0410 - accuracy: 0.9847 - 14s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.0374 - accuracy: 0.9860 - 14s/epoch - 30ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.0332 - accuracy: 0.9875 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.0261 - accuracy: 0.9893 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.0247 - accuracy: 0.9905 - 14s/epoch - 30ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.0274 - accuracy: 0.9893 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.0210 - accuracy: 0.9917 - 14s/epoch - 29ms/step\n",
            "accuracy: 98.87%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 16s - loss: 0.2851 - accuracy: 0.8666 - 16s/epoch - 33ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.0986 - accuracy: 0.9610 - 14s/epoch - 30ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.0745 - accuracy: 0.9722 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.0557 - accuracy: 0.9791 - 14s/epoch - 29ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.0390 - accuracy: 0.9852 - 14s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.0366 - accuracy: 0.9863 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.0385 - accuracy: 0.9858 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.0274 - accuracy: 0.9895 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.0269 - accuracy: 0.9890 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.0251 - accuracy: 0.9901 - 14s/epoch - 29ms/step\n",
            "accuracy: 98.97%\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 16s - loss: 0.3088 - accuracy: 0.8509 - 16s/epoch - 32ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 14s - loss: 0.1047 - accuracy: 0.9592 - 14s/epoch - 29ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 14s - loss: 0.0664 - accuracy: 0.9753 - 14s/epoch - 29ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 14s - loss: 0.0561 - accuracy: 0.9794 - 14s/epoch - 30ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 14s - loss: 0.0417 - accuracy: 0.9843 - 14s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 14s - loss: 0.0388 - accuracy: 0.9851 - 14s/epoch - 29ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 14s - loss: 0.0353 - accuracy: 0.9856 - 14s/epoch - 29ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 14s - loss: 0.0305 - accuracy: 0.9879 - 14s/epoch - 29ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 14s - loss: 0.0246 - accuracy: 0.9907 - 14s/epoch - 30ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 14s - loss: 0.0424 - accuracy: 0.9845 - 14s/epoch - 29ms/step\n",
            "accuracy: 99.03%\n",
            "Model Accuracy List:  [96.95456624031067, 97.32900857925415, 98.86826872825623, 98.96813035011292, 99.03470277786255]\n",
            "98.23% (+/- 0.90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU 30% DATA BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_fold_before_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_before.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3otqkeRUjs1",
        "outputId": "621fd6e7-2539-4e85-bc96-eb5136e943e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 55s - loss: 0.6835 - accuracy: 0.5629 - 55s/epoch - 115ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.6779 - accuracy: 0.5384 - 49s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.6736 - accuracy: 0.5355 - 49s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.6707 - accuracy: 0.5468 - 49s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.6682 - accuracy: 0.5507 - 49s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.6659 - accuracy: 0.5562 - 49s/epoch - 103ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.6638 - accuracy: 0.5631 - 49s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.6617 - accuracy: 0.5761 - 49s/epoch - 103ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.6598 - accuracy: 0.5768 - 49s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.6580 - accuracy: 0.5953 - 49s/epoch - 102ms/step\n",
            "accuracy: 59.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 53s - loss: 0.7037 - accuracy: 0.4358 - 53s/epoch - 111ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.6963 - accuracy: 0.4859 - 49s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.6908 - accuracy: 0.4932 - 49s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.6864 - accuracy: 0.4791 - 49s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.6825 - accuracy: 0.4769 - 49s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.6785 - accuracy: 0.4852 - 49s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.6746 - accuracy: 0.5027 - 49s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.6716 - accuracy: 0.5317 - 49s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.6689 - accuracy: 0.5539 - 49s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.6663 - accuracy: 0.5679 - 49s/epoch - 102ms/step\n",
            "accuracy: 58.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 52s - loss: 0.6904 - accuracy: 0.5155 - 52s/epoch - 108ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.6837 - accuracy: 0.5266 - 49s/epoch - 101ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 48s - loss: 0.6791 - accuracy: 0.5349 - 48s/epoch - 101ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 48s - loss: 0.6747 - accuracy: 0.5439 - 48s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.6713 - accuracy: 0.5554 - 49s/epoch - 101ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.6684 - accuracy: 0.5623 - 49s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.6658 - accuracy: 0.5732 - 49s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.6630 - accuracy: 0.5825 - 49s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 48s - loss: 0.6598 - accuracy: 0.5899 - 48s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.6575 - accuracy: 0.5960 - 49s/epoch - 101ms/step\n",
            "accuracy: 60.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_16_layer_call_fn, gru_cell_16_layer_call_and_return_conditional_losses, gru_cell_17_layer_call_fn, gru_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 52s - loss: 0.6950 - accuracy: 0.4825 - 52s/epoch - 108ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.6853 - accuracy: 0.5092 - 49s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.6812 - accuracy: 0.5108 - 49s/epoch - 101ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.6778 - accuracy: 0.5107 - 49s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.6748 - accuracy: 0.5126 - 49s/epoch - 101ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.6719 - accuracy: 0.5185 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.6685 - accuracy: 0.5321 - 49s/epoch - 101ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.6653 - accuracy: 0.5548 - 49s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.6626 - accuracy: 0.5816 - 49s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.6602 - accuracy: 0.5858 - 49s/epoch - 101ms/step\n",
            "accuracy: 59.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_18_layer_call_fn, gru_cell_18_layer_call_and_return_conditional_losses, gru_cell_19_layer_call_fn, gru_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 52s - loss: 0.6733 - accuracy: 0.5425 - 52s/epoch - 108ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.6696 - accuracy: 0.5711 - 49s/epoch - 101ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.6665 - accuracy: 0.5869 - 49s/epoch - 101ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.6639 - accuracy: 0.5963 - 49s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.6615 - accuracy: 0.6000 - 49s/epoch - 101ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.6591 - accuracy: 0.6051 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.6569 - accuracy: 0.6092 - 49s/epoch - 101ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.6548 - accuracy: 0.6118 - 49s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.6528 - accuracy: 0.6124 - 49s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.6510 - accuracy: 0.6146 - 49s/epoch - 101ms/step\n",
            "accuracy: 61.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [59.27774906158447, 58.96155834197998, 60.60580611228943, 59.182822704315186, 61.00524067878723]\n",
            "59.81% (+/- 0.83%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU 30% DATA AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.GRU(100, return_sequences=True, activation='tanh'),\n",
        "            layers.GRU(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_fold_after_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_after.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPxJhgLFUmrc",
        "outputId": "de5db200-f947-44ee-9b4a-acb499e8919a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 53s - loss: 0.3392 - accuracy: 0.8323 - 53s/epoch - 110ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.1004 - accuracy: 0.9607 - 49s/epoch - 101ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.0736 - accuracy: 0.9679 - 49s/epoch - 101ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.0512 - accuracy: 0.9797 - 49s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.0412 - accuracy: 0.9845 - 49s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.0307 - accuracy: 0.9882 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.0254 - accuracy: 0.9901 - 49s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.0267 - accuracy: 0.9896 - 49s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.0215 - accuracy: 0.9912 - 49s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.0213 - accuracy: 0.9915 - 49s/epoch - 103ms/step\n",
            "accuracy: 99.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_22_layer_call_fn, gru_cell_22_layer_call_and_return_conditional_losses, gru_cell_23_layer_call_fn, gru_cell_23_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 52s - loss: 0.3414 - accuracy: 0.8312 - 52s/epoch - 109ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.1031 - accuracy: 0.9596 - 49s/epoch - 101ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.0704 - accuracy: 0.9695 - 49s/epoch - 101ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.0542 - accuracy: 0.9789 - 49s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.0459 - accuracy: 0.9824 - 49s/epoch - 101ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.0332 - accuracy: 0.9871 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.0268 - accuracy: 0.9894 - 49s/epoch - 101ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 48s - loss: 0.0228 - accuracy: 0.9908 - 48s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 48s - loss: 0.0200 - accuracy: 0.9919 - 48s/epoch - 101ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.0193 - accuracy: 0.9923 - 49s/epoch - 101ms/step\n",
            "accuracy: 98.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_24_layer_call_fn, gru_cell_24_layer_call_and_return_conditional_losses, gru_cell_25_layer_call_fn, gru_cell_25_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 53s - loss: 0.3234 - accuracy: 0.8416 - 53s/epoch - 110ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.1032 - accuracy: 0.9593 - 49s/epoch - 102ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.0728 - accuracy: 0.9691 - 49s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.0528 - accuracy: 0.9780 - 49s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.0435 - accuracy: 0.9838 - 49s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.0371 - accuracy: 0.9858 - 49s/epoch - 102ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.0313 - accuracy: 0.9879 - 49s/epoch - 102ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.0247 - accuracy: 0.9898 - 49s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.0233 - accuracy: 0.9905 - 49s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.0218 - accuracy: 0.9913 - 49s/epoch - 102ms/step\n",
            "accuracy: 98.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_26_layer_call_fn, gru_cell_26_layer_call_and_return_conditional_losses, gru_cell_27_layer_call_fn, gru_cell_27_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 53s - loss: 0.3090 - accuracy: 0.8536 - 53s/epoch - 111ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 49s - loss: 0.1067 - accuracy: 0.9573 - 49s/epoch - 103ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.0722 - accuracy: 0.9679 - 49s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.0558 - accuracy: 0.9779 - 49s/epoch - 101ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.0458 - accuracy: 0.9823 - 49s/epoch - 101ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.0384 - accuracy: 0.9848 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.0277 - accuracy: 0.9896 - 49s/epoch - 101ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.0263 - accuracy: 0.9892 - 49s/epoch - 101ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.0216 - accuracy: 0.9914 - 49s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 49s - loss: 0.0188 - accuracy: 0.9924 - 49s/epoch - 101ms/step\n",
            "accuracy: 98.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_28_layer_call_fn, gru_cell_28_layer_call_and_return_conditional_losses, gru_cell_29_layer_call_fn, gru_cell_29_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 53s - loss: 0.3504 - accuracy: 0.8306 - 53s/epoch - 111ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 50s - loss: 0.1082 - accuracy: 0.9580 - 50s/epoch - 104ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 49s - loss: 0.0767 - accuracy: 0.9665 - 49s/epoch - 102ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 49s - loss: 0.0519 - accuracy: 0.9785 - 49s/epoch - 102ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 49s - loss: 0.0391 - accuracy: 0.9851 - 49s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 49s - loss: 0.0341 - accuracy: 0.9863 - 49s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 49s - loss: 0.0290 - accuracy: 0.9889 - 49s/epoch - 101ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 49s - loss: 0.0250 - accuracy: 0.9907 - 49s/epoch - 102ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 49s - loss: 0.0226 - accuracy: 0.9909 - 49s/epoch - 102ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 51s - loss: 0.0206 - accuracy: 0.9931 - 51s/epoch - 105ms/step\n",
            "accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_30_layer_call_fn, gru_cell_30_layer_call_and_return_conditional_losses, gru_cell_31_layer_call_fn, gru_cell_31_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [99.20119643211365, 98.56881499290466, 98.87658953666687, 98.29408526420593, 99.17616844177246]\n",
            "98.82% (+/- 0.35%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_30_layer_call_fn, gru_cell_30_layer_call_and_return_conditional_losses, gru_cell_31_layer_call_fn, gru_cell_31_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM 30% DATA BEFORE TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.SGD(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_fold_before_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_before.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oomlh4SBUnkI",
        "outputId": "68ebcade-cffa-4afc-d231-6607df19d9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.6919 - accuracy: 0.5119 - 56s/epoch - 116ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.6842 - accuracy: 0.5163 - 53s/epoch - 109ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.6777 - accuracy: 0.5502 - 53s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 56s - loss: 0.6716 - accuracy: 0.5928 - 56s/epoch - 117ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 54s - loss: 0.6656 - accuracy: 0.6242 - 54s/epoch - 112ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 56s - loss: 0.6595 - accuracy: 0.6517 - 56s/epoch - 116ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 72s - loss: 0.6533 - accuracy: 0.6656 - 72s/epoch - 151ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 74s - loss: 0.6477 - accuracy: 0.6782 - 74s/epoch - 153ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 58s - loss: 0.6423 - accuracy: 0.6830 - 58s/epoch - 120ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.6369 - accuracy: 0.6868 - 53s/epoch - 110ms/step\n",
            "accuracy: 69.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 57s - loss: 0.6876 - accuracy: 0.5223 - 57s/epoch - 119ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.6807 - accuracy: 0.5136 - 53s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.6749 - accuracy: 0.5314 - 53s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.6694 - accuracy: 0.5919 - 53s/epoch - 111ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.6648 - accuracy: 0.6497 - 53s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.6604 - accuracy: 0.6754 - 53s/epoch - 110ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.6562 - accuracy: 0.6897 - 53s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.6519 - accuracy: 0.6955 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.6475 - accuracy: 0.6988 - 53s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.6431 - accuracy: 0.6995 - 53s/epoch - 111ms/step\n",
            "accuracy: 70.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.6809 - accuracy: 0.5146 - 56s/epoch - 117ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.6747 - accuracy: 0.5166 - 53s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.6704 - accuracy: 0.5364 - 53s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.6666 - accuracy: 0.5755 - 53s/epoch - 109ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.6630 - accuracy: 0.6123 - 53s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 52s - loss: 0.6593 - accuracy: 0.6297 - 52s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 52s - loss: 0.6556 - accuracy: 0.6515 - 52s/epoch - 109ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.6518 - accuracy: 0.6626 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.6480 - accuracy: 0.6715 - 53s/epoch - 110ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.6441 - accuracy: 0.6790 - 53s/epoch - 110ms/step\n",
            "accuracy: 68.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.6917 - accuracy: 0.4997 - 56s/epoch - 116ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.6870 - accuracy: 0.5115 - 53s/epoch - 109ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.6820 - accuracy: 0.5197 - 53s/epoch - 109ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.6784 - accuracy: 0.5338 - 53s/epoch - 110ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.6750 - accuracy: 0.5495 - 53s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.6716 - accuracy: 0.5736 - 53s/epoch - 110ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 55s - loss: 0.6682 - accuracy: 0.5955 - 55s/epoch - 114ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.6647 - accuracy: 0.6208 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 54s - loss: 0.6612 - accuracy: 0.6342 - 54s/epoch - 112ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.6578 - accuracy: 0.6511 - 53s/epoch - 109ms/step\n",
            "accuracy: 64.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.7016 - accuracy: 0.4895 - 56s/epoch - 117ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.6881 - accuracy: 0.5617 - 53s/epoch - 109ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 52s - loss: 0.6830 - accuracy: 0.6586 - 52s/epoch - 109ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.6795 - accuracy: 0.5811 - 53s/epoch - 109ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.6763 - accuracy: 0.5735 - 53s/epoch - 109ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.6733 - accuracy: 0.5775 - 53s/epoch - 110ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.6702 - accuracy: 0.6092 - 53s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.6669 - accuracy: 0.6386 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.6635 - accuracy: 0.6539 - 53s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.6600 - accuracy: 0.6744 - 53s/epoch - 111ms/step\n",
            "accuracy: 67.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [69.33766007423401, 70.37776708602905, 68.27827095985413, 64.808189868927, 67.55430102348328]\n",
            "68.07% (+/- 1.89%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM 30% DATA AFTER TUNING\n",
        "\n",
        "fold_number = 0\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)                                            \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_test):                                     \n",
        "    x_train_fold, x_test_fold = x_test[train_index], x_test[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_test[train_index], y_test[test_index]  \n",
        "    model = keras.Sequential(                                                   \n",
        "        [\n",
        "            keras.Input(shape=(None,5)),\n",
        "            layers.LSTM(100, return_sequences=True, activation='tanh'),\n",
        "            layers.LSTM(100, activation='tanh'),\n",
        "            layers.Dense(2)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer = keras.optimizers.Adam(lr=3e-4),\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    model.fit(x_train_fold, y_train_fold, batch_size=100, epochs=10, verbose=2)\n",
        "    scores = model.evaluate(x_test[test_index], y_test[test_index], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_fold_after_\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_after.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6eKWTaBtIE0",
        "outputId": "cd05159d-f758-4765-909f-6d4184a3a13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "481/481 - 58s - loss: 0.3683 - accuracy: 0.8278 - 58s/epoch - 121ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.1449 - accuracy: 0.9459 - 53s/epoch - 111ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.1234 - accuracy: 0.9550 - 53s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.0788 - accuracy: 0.9688 - 53s/epoch - 110ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.0683 - accuracy: 0.9727 - 53s/epoch - 111ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.0539 - accuracy: 0.9798 - 53s/epoch - 110ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.0529 - accuracy: 0.9808 - 53s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.0415 - accuracy: 0.9842 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.0358 - accuracy: 0.9859 - 53s/epoch - 110ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.0322 - accuracy: 0.9875 - 53s/epoch - 110ms/step\n",
            "accuracy: 99.03%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 57s - loss: 0.3449 - accuracy: 0.8414 - 57s/epoch - 118ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.1376 - accuracy: 0.9476 - 53s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.1031 - accuracy: 0.9600 - 53s/epoch - 111ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 52s - loss: 0.0804 - accuracy: 0.9673 - 52s/epoch - 109ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 52s - loss: 0.0728 - accuracy: 0.9716 - 52s/epoch - 108ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 52s - loss: 0.0523 - accuracy: 0.9802 - 52s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.0470 - accuracy: 0.9820 - 53s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.0424 - accuracy: 0.9838 - 53s/epoch - 109ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.0357 - accuracy: 0.9868 - 53s/epoch - 110ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 52s - loss: 0.0358 - accuracy: 0.9852 - 52s/epoch - 109ms/step\n",
            "accuracy: 98.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.3597 - accuracy: 0.8364 - 56s/epoch - 117ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.1460 - accuracy: 0.9454 - 53s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.1007 - accuracy: 0.9619 - 53s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.0761 - accuracy: 0.9691 - 53s/epoch - 109ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.1073 - accuracy: 0.9620 - 53s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.0599 - accuracy: 0.9758 - 53s/epoch - 110ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.0492 - accuracy: 0.9808 - 53s/epoch - 110ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.0428 - accuracy: 0.9839 - 53s/epoch - 111ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.0379 - accuracy: 0.9854 - 53s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 54s - loss: 0.0309 - accuracy: 0.9884 - 54s/epoch - 111ms/step\n",
            "accuracy: 99.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 57s - loss: 0.3744 - accuracy: 0.8224 - 57s/epoch - 118ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 52s - loss: 0.1429 - accuracy: 0.9469 - 52s/epoch - 109ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 54s - loss: 0.1131 - accuracy: 0.9565 - 54s/epoch - 112ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.0796 - accuracy: 0.9671 - 53s/epoch - 109ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 52s - loss: 0.0855 - accuracy: 0.9697 - 52s/epoch - 109ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 52s - loss: 0.0529 - accuracy: 0.9797 - 52s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.0487 - accuracy: 0.9818 - 53s/epoch - 109ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.0381 - accuracy: 0.9854 - 53s/epoch - 109ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 52s - loss: 0.0342 - accuracy: 0.9869 - 52s/epoch - 109ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.0456 - accuracy: 0.9835 - 53s/epoch - 110ms/step\n",
            "accuracy: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 - 56s - loss: 0.3631 - accuracy: 0.8278 - 56s/epoch - 117ms/step\n",
            "Epoch 2/10\n",
            "481/481 - 53s - loss: 0.1454 - accuracy: 0.9450 - 53s/epoch - 110ms/step\n",
            "Epoch 3/10\n",
            "481/481 - 53s - loss: 0.1124 - accuracy: 0.9574 - 53s/epoch - 110ms/step\n",
            "Epoch 4/10\n",
            "481/481 - 53s - loss: 0.0845 - accuracy: 0.9661 - 53s/epoch - 110ms/step\n",
            "Epoch 5/10\n",
            "481/481 - 53s - loss: 0.0688 - accuracy: 0.9719 - 53s/epoch - 110ms/step\n",
            "Epoch 6/10\n",
            "481/481 - 53s - loss: 0.0562 - accuracy: 0.9788 - 53s/epoch - 109ms/step\n",
            "Epoch 7/10\n",
            "481/481 - 53s - loss: 0.0497 - accuracy: 0.9811 - 53s/epoch - 109ms/step\n",
            "Epoch 8/10\n",
            "481/481 - 53s - loss: 0.0539 - accuracy: 0.9807 - 53s/epoch - 110ms/step\n",
            "Epoch 9/10\n",
            "481/481 - 53s - loss: 0.0368 - accuracy: 0.9859 - 53s/epoch - 110ms/step\n",
            "Epoch 10/10\n",
            "481/481 - 53s - loss: 0.0364 - accuracy: 0.9859 - 53s/epoch - 110ms/step\n",
            "accuracy: 99.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy List:  [99.02645945549011, 98.71026873588562, 99.26770329475403, 99.05134439468384, 99.27602410316467]\n",
            "99.07% (+/- 0.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN FOLD 30% BEFORE TUNING======================\n",
        "file_rnn_fold_30_data_before = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_fold_before_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_30_data_before = [(pickle.load(open(file_rnn_fold_30_data_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_30_data_before = [(loaded_model_rnn_30_data_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_30_data_before = [(np.argmax(y_pred_rnn_30_data_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_30_data_before[ypvc] = np.reshape(y_pred_values_rnn_30_data_before[ypvc],(-1,1))\n",
        "result_rnn_30_data_before = [(classification_report(y_test, y_pred_values_rnn_30_data_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#RNN FOLD 30% AFTER TUNING=======================\n",
        "file_rnn_fold_30_data_after = [(\"drive/MyDrive/Dann Dataset/RNN Model/rnn_model_30%data_fold_after_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_rnn_30_data_after = [(pickle.load(open(file_rnn_fold_30_data_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_rnn_30_data_after = [(loaded_model_rnn_30_data_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_rnn_30_data_after = [(np.argmax(y_pred_rnn_30_data_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_rnn_30_data_after[ypvc] = np.reshape(y_pred_values_rnn_30_data_after[ypvc],(-1,1))\n",
        "result_rnn_30_data_after = [(classification_report(y_test, y_pred_values_rnn_30_data_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU 30% FOLD BEFORE TUNING======================\n",
        "file_gru_fold_30_data_before = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_fold_before_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_30_data_before = [(pickle.load(open(file_gru_fold_30_data_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_30_data_before = [(loaded_model_gru_30_data_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_30_data_before = [(np.argmax(y_pred_gru_30_data_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_30_data_before[ypvc] = np.reshape(y_pred_values_gru_30_data_before[ypvc],(-1,1))\n",
        "result_gru_30_data_before = [(classification_report(y_test, y_pred_values_gru_30_data_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#GRU 30% FOLD AFTER TUNING=======================\n",
        "file_gru_fold_30_data_after = [(\"drive/MyDrive/Dann Dataset/GRU Model/gru_model_30%data_fold_after_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_gru_30_data_after = [(pickle.load(open(file_gru_fold_30_data_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_gru_30_data_after = [(loaded_model_gru_30_data_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_gru_30_data_after = [(np.argmax(y_pred_gru_30_data_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_gru_30_data_after[ypvc] = np.reshape(y_pred_values_gru_30_data_after[ypvc],(-1,1))\n",
        "result_gru_30_data_after = [(classification_report(y_test, y_pred_values_gru_30_data_after[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM 30% FOLD BEFORE TUNING========================= \n",
        "file_lstm_fold_30_data_before = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_fold_before_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_30_data_before = [(pickle.load(open(file_lstm_fold_30_data_before[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_30_data_before = [(loaded_model_lstm_30_data_before[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_30_data_before = [(np.argmax(y_pred_lstm_30_data_before[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_30_data_before[ypvc] = np.reshape(y_pred_values_lstm_30_data_before[ypvc],(-1,1))\n",
        "result_lstm_30_data_before = [(classification_report(y_test, y_pred_values_lstm_30_data_before[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "#LSTM 30% FOLD AFTER TUNING========================= \n",
        "file_lstm_fold_30_data_after = [(\"drive/MyDrive/Dann Dataset/LSTM Model/lstm_model_30%data_fold_after_\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_model_lstm_30_data_after = [(pickle.load(open(file_lstm_fold_30_data_after[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_lstm_30_data_after = [(loaded_model_lstm_30_data_after[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_lstm_30_data_after = [(np.argmax(y_pred_lstm_30_data_after[ypv], axis = 1)) for ypv in range(total_fold)]\n",
        "for ypvc in range(total_fold):\n",
        "  y_pred_values_lstm_30_data_after[ypvc] = np.reshape(y_pred_values_lstm_30_data_after[ypvc],(-1,1))\n",
        "result_lstm_30_data_after = [(classification_report(y_test, y_pred_values_lstm_30_data_after[res], output_dict = True)) for res in range(total_fold)]"
      ],
      "metadata": {
        "id": "nLxKZgi-U3tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de24cb1-8f4c-464a-b6f7-0d3793dfb211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 16s 9ms/step\n",
            "1878/1878 [==============================] - 16s 8ms/step\n",
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 18s 9ms/step\n",
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 21s 11ms/step\n",
            "1878/1878 [==============================] - 17s 9ms/step\n",
            "1878/1878 [==============================] - 34s 18ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 33s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 32s 17ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n",
            "1878/1878 [==============================] - 39s 20ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n",
            "1878/1878 [==============================] - 37s 19ms/step\n",
            "1878/1878 [==============================] - 38s 19ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n",
            "1878/1878 [==============================] - 39s 20ms/step\n",
            "1878/1878 [==============================] - 38s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_list_30_data_before = {}\n",
        "precision_list_30_data_after = {}\n",
        "recall_list_30_data_before = {}\n",
        "recall_list_30_data_after = {}\n",
        "accuracy_list_30_data_before = {}\n",
        "accuracy_list_30_data_after = {}\n",
        "f1_list_30_data_before = {}\n",
        "f1_list_30_data_after = {}"
      ],
      "metadata": {
        "id": "qwTq8KXLU4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sco in range(total_fold):\n",
        "  precision_list_30_data_before[(sco+1)] = [result_rnn_30_data_before[sco]['weighted avg']['precision'] , result_gru_30_data_before[sco]['weighted avg']['precision'], result_lstm_30_data_before[sco]['weighted avg']['precision']]\n",
        "  precision_list_30_data_after[(sco+1)] = [result_rnn_30_data_after[sco]['weighted avg']['precision'] , result_gru_30_data_after[sco]['weighted avg']['precision'], result_lstm_30_data_after[sco]['weighted avg']['precision']]\n",
        "  recall_list_30_data_before[(sco+1)] = [result_rnn_30_data_before[sco]['weighted avg']['recall'] , result_gru_30_data_before[sco]['weighted avg']['recall'], result_lstm_30_data_before[sco]['weighted avg']['recall']]\n",
        "  recall_list_30_data_after[(sco+1)] = [result_rnn_30_data_after[sco]['weighted avg']['recall'] , result_gru_30_data_after[sco]['weighted avg']['recall'], result_lstm_30_data_after[sco]['weighted avg']['recall']]\n",
        "  f1_list_30_data_before[(sco+1)] = [result_rnn_30_data_before[sco]['weighted avg']['f1-score'] , result_gru_30_data_before[sco]['weighted avg']['f1-score'], result_lstm_30_data_before[sco]['weighted avg']['f1-score']]\n",
        "  f1_list_30_data_after[(sco+1)] = [result_rnn_30_data_after[sco]['weighted avg']['f1-score'] , result_gru_30_data_after[sco]['weighted avg']['f1-score'], result_lstm_30_data_after[sco]['weighted avg']['f1-score']]\n",
        "  accuracy_list_30_data_before[(sco+1)] = [result_rnn_30_data_before[sco]['accuracy'] , result_gru_30_data_before[sco]['accuracy'], result_lstm_30_data_before[sco]['accuracy']]\n",
        "  accuracy_list_30_data_after[(sco+1)] = [result_rnn_30_data_after[sco]['accuracy'] , result_gru_30_data_after[sco]['accuracy'], result_lstm_30_data_after[sco]['accuracy']]"
      ],
      "metadata": {
        "id": "KWcMF3urU9dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold 30% Data Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_30_data_before.items():\n",
        "    rnn_fold_data_before, gru_fold_data_before, lstm_fold_data_before = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_before,\".3f\"), format(gru_fold_data_before,\".3f\"), format(lstm_fold_data_before,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Precision K-Fold 30% Data Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in precision_list_30_data_after.items():\n",
        "    rnn_fold_data_after, gru_fold_data_after, lstm_fold_data_after = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_before,\".3f\"), format(gru_fold_data_before,\".3f\"), format(lstm_fold_data_before,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold 30% Data Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_30_data_before.items():\n",
        "    rnn_fold_data_before, gru_fold_data_before, lstm_fold_data_before = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_before,\".3f\"), format(gru_fold_data_before,\".3f\"), format(lstm_fold_data_before,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Recall K-Fold 30% Data Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in recall_list_30_data_after.items():\n",
        "    rnn_fold_data_after, gru_fold_data_after, lstm_fold_data_after = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_after,\".3f\"), format(gru_fold_data_after,\".3f\"), format(lstm_fold_data_after,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold 30% Data Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_30_data_before.items():\n",
        "    rnn_fold_data_before, gru_fold_data_before, lstm_fold_data_before = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_before,\".3f\"), format(gru_fold_data_before,\".3f\"), format(lstm_fold_data_before,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"Accuracy K-Fold 30% Data Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in accuracy_list_30_data_after.items():\n",
        "    rnn_fold_data_after, gru_fold_data_after, lstm_fold_data_after = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_after,\".3f\"), format(gru_fold_data_after,\".3f\"), format(lstm_fold_data_after,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold 30% Data Sebelum Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_30_data_before.items():\n",
        "    rnn_fold_data_before, gru_fold_data_before, lstm_fold_data_before = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_before,\".3f\"), format(gru_fold_data_before,\".3f\"), format(lstm_fold_data_before,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<5} {:<0}\".format(\"\",\"F1-Score K-Fold 30% Data Sesudah Tuning\"))\n",
        "print (\"{:<8} {:<10} {:<10} {:<10}\".format('Fold','RNN','GRU','LSTM'))\n",
        "for k, v in f1_list_30_data_after.items():\n",
        "    rnn_fold_data_after, gru_fold_data_after, lstm_fold_data_after = v\n",
        "    print (\"{:<8} {:<10} {:<10} {:<10}\".format(k, format(rnn_fold_data_after,\".3f\"), format(gru_fold_data_after,\".3f\"), format(lstm_fold_data_after,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "SyNmORaLVA8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf8ebcc-da28-4886-c094-75ed21df7367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Precision K-Fold 30% Data Sebelum Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.900      0.597      0.727     \n",
            "2        0.865      0.586      0.744     \n",
            "3        0.845      0.620      0.693     \n",
            "4        0.870      0.596      0.661     \n",
            "5        0.738      0.641      0.679     \n",
            "\n",
            "\n",
            "      Precision K-Fold 30% Data Sesudah Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.738      0.641      0.679     \n",
            "2        0.738      0.641      0.679     \n",
            "3        0.738      0.641      0.679     \n",
            "4        0.738      0.641      0.679     \n",
            "5        0.738      0.641      0.679     \n",
            "\n",
            "\n",
            "      Recall K-Fold 30% Data Sebelum Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.897      0.594      0.690     \n",
            "2        0.865      0.580      0.702     \n",
            "3        0.845      0.602      0.680     \n",
            "4        0.845      0.593      0.653     \n",
            "5        0.723      0.616      0.673     \n",
            "\n",
            "\n",
            "      Recall K-Fold 30% Data Sesudah Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.970      0.991      0.991     \n",
            "2        0.973      0.986      0.988     \n",
            "3        0.989      0.989      0.993     \n",
            "4        0.990      0.981      0.990     \n",
            "5        0.991      0.994      0.991     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold 30% Data Sebelum Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.897      0.594      0.690     \n",
            "2        0.865      0.580      0.702     \n",
            "3        0.845      0.602      0.680     \n",
            "4        0.845      0.593      0.653     \n",
            "5        0.723      0.616      0.673     \n",
            "\n",
            "\n",
            "      Accuracy K-Fold 30% Data Sesudah Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.970      0.991      0.991     \n",
            "2        0.973      0.986      0.988     \n",
            "3        0.989      0.989      0.993     \n",
            "4        0.990      0.981      0.990     \n",
            "5        0.991      0.994      0.991     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold 30% Data Sebelum Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.897      0.593      0.679     \n",
            "2        0.865      0.575      0.690     \n",
            "3        0.845      0.590      0.676     \n",
            "4        0.842      0.591      0.649     \n",
            "5        0.720      0.601      0.672     \n",
            "\n",
            "\n",
            "      F1-Score K-Fold 30% Data Sesudah Tuning\n",
            "Fold     RNN        GRU        LSTM      \n",
            "1        0.970      0.991      0.991     \n",
            "2        0.973      0.986      0.988     \n",
            "3        0.989      0.989      0.993     \n",
            "4        0.990      0.981      0.990     \n",
            "5        0.991      0.994      0.991     \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
